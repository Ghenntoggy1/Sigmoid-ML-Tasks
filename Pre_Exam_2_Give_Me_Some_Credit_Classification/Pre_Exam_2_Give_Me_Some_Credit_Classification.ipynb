{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c280d771",
   "metadata": {},
   "source": [
    "# Pre-Examination #2 - Give Me Some Credit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "905d6179",
   "metadata": {},
   "source": [
    "## Dataset Description:\n",
    "### Dataset Kaggle Link:\n",
    "[Kaggle Give Me Some Credit](https://www.kaggle.com/competitions/GiveMeSomeCredit/overview)\n",
    "\n",
    "### Features:\n",
    "| Feature Name                        | Description                                                                                                                                              | Type       |\n",
    "|--------------------------------------|----------------------------------------------------------------------------------------------------------------------------------------------------------|------------|\n",
    "| `SeriousDlqin2yrs`                     | Person experienced 90 days past due delinquency or worse                                                                                               | Y/N        |\n",
    "| `RevolvingUtilizationOfUnsecuredLines` | Total balance on credit cards and personal lines of credit except real estate and no installment debt like car loans divided by the sum of credit limits | percentage |\n",
    "| `age`                                  | Age of borrower in years                                                                                                                                 | integer    |\n",
    "| `NumberOfTime30-59DaysPastDueNotWorse` | Number of times borrower has been 30-59 days past due but no worse in the last 2 years.                                                                  | integer    |\n",
    "| `DebtRatio`                            | Monthly debt payments, alimony,living costs divided by monthy gross income                                                                               | percentage |\n",
    "| `MonthlyIncome`                        | Monthly income                                                                                                                                           | real       |\n",
    "| `NumberOfOpenCreditLinesAndLoans`      | Number of Open loans (installment like car loan or mortgage) and Lines of credit (e.g. credit cards)                                                     | integer    |\n",
    "| `NumberOfTimes90DaysLate`              | Number of times borrower has been 90 days or more past due.                                                                                              | integer    |\n",
    "| `NumberRealEstateLoansOrLines`         | Number of mortgage and real estate loans including home equity lines of credit                                                                           | integer    |\n",
    "| `NumberOfTime60-89DaysPastDueNotWorse` | Number of times borrower has been 60-89 days past due but no worse in the last 2 years.                                                                  | integer    |\n",
    "| `NumberOfDependents`                   | Number of dependents in family excluding themselves (spouse, children etc.)                                                                              | integer    |\n",
    "\n",
    "### Target:\n",
    "There is a Target Column in the dataset - `SeriousDlqin2yrs`, of datatype `boolean`, with 2 possible values - `Y/N` or, respectivelly, `1/0`. This column is showing if a person experienced 90 days past due delinquency or worse. Therefore, this problem is a Supervised Classification Machine Learning Problem.\n",
    "\n",
    "### Problem Description:\n",
    "Banks, in order to determine whether or not a loan should be granted to borrowers, require prior knowledge about borrower's capability to return the money they borrowed. For this, they use a system based on credibility that will offers a credit/reputation to borrowers. This credit is based on different criteria, such as: previous loans, overdebt, concurrent loans, and so on. This dataset is built upon the idea of prediction of probability that potential borrowers will experience financial distress in the next two years, enabling banks to decide better to grant a loan to that specific person or not. The task is to build a model that will predict this based on several features, like **Number of Days Overdue**, **Monthly Income** and others."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ffe90a7",
   "metadata": {},
   "source": [
    "## Importing Prerequisites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97a5d3c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Data Structures\n",
    "import pandas as pd\n",
    "import dask.dataframe as dd\n",
    "\n",
    "# Import Data Manipulation Libraries\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "# Import Base Classes for Type Annotation\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from numbers import Number\n",
    "\n",
    "# Import Structure Manipulation Methods\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, OneHotEncoder, OrdinalEncoder, FunctionTransformer\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.impute import KNNImputer, SimpleImputer\n",
    "# from reparo import CDI, MICE\n",
    "\n",
    "# Import Visualization Libs\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import seaborn as sns\n",
    "sns.set_style(style=\"whitegrid\")\n",
    "sns.set_palette('bright')\n",
    "\n",
    "# Import Outlier Detection\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "from sklearn.ensemble import IsolationForest\n",
    "\n",
    "# Import Feature Selection Methods\n",
    "from kydavra import PValueSelector\n",
    "from sklearn.feature_selection import RFECV\n",
    "\n",
    "# Import Hyperparameter Tuning\n",
    "import optuna\n",
    "\n",
    "# Import ML Models\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# Import Interpretation Metrics\n",
    "from sklearn.metrics import classification_report, accuracy_score, f1_score, precision_score, recall_score, confusion_matrix, ConfusionMatrixDisplay, RocCurveDisplay, roc_curve, average_precision_score, roc_auc_score, precision_recall_curve, PrecisionRecallDisplay\n",
    "\n",
    "# from lime.lime_tabular import LimeTabularExplainer\n",
    "# import shap\n",
    "\n",
    "# Import Custom Utils\n",
    "import swifter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "434344a7",
   "metadata": {},
   "source": [
    "## Dataset Loading\n",
    "Since both training and test datasets are not very large, basic `pandas.DataFrame` will be sufficient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c204fd99",
   "metadata": {},
   "outputs": [],
   "source": [
    "credit_train_zip: pd.DataFrame = pd.read_csv(filepath_or_buffer='dataset/cs-training.csv', sep=',')\n",
    "credit_train_zip_eda: pd.DataFrame = credit_train_zip.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dd6cfa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "credit_test_zip: pd.DataFrame = pd.read_csv(filepath_or_buffer='dataset/cs-test.csv', sep=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eb67c76",
   "metadata": {},
   "source": [
    "### Basic Dataset Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09cf3030",
   "metadata": {},
   "outputs": [],
   "source": [
    "credit_train_zip_eda.head(n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87ded4b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "credit_train_zip_eda.tail(n=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ba610de",
   "metadata": {},
   "source": [
    "As it may be seen, several features are present in the dataset. At the same time, several `NaN` values have been noticed in `MonthlyIncome` and `NumberOfDependents` columns. Besides that, no feature scaling was perfomed on this dataset. Also, first column of the dataset - `Unnamed: 0`, that is a result of the `pd.readcsv()` function, is a replacement for the first missing name in the original `.csv` file, that, most probably, is just the ID column for the samples in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a732059",
   "metadata": {},
   "outputs": [],
   "source": [
    "credit_train_zip_eda.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ca8570d",
   "metadata": {},
   "source": [
    "There are no columns of `object` data type, which is often used for columns of `String` data type. Besides that there are 8 columns of `int64` data type and 4 columns of `float64` data type. Also, there are 2 columns with missing values - `MonthlyIncome` and `NumberOfDependents`, as it was mentioned in the previous paragraph. In total there are 11 Features and 1 Target Variable - `SeriousDlqin2yrs`. Again, the memory usage of this specific dataset is $\\approx$ 13.7 MB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a31868d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Train Dataset Shape: {credit_train_zip_eda.shape[0]} samples, {credit_train_zip_eda.shape[1]} columns\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9e30388",
   "metadata": {},
   "source": [
    "As it may be seen, train dataset contains exactly 150000 training samples and 12 columns, as it was mentioned previously, 11 features and 1 target variable column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48ce2c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "credit_train_zip_eda.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3f0686d",
   "metadata": {},
   "source": [
    "After a brief analysis of the described dataset, were derived several conclusions:\n",
    "1. Dataset is highly imbalanced, since target variable `SeriousDlqin2yrs` contains at least 75% of negative samples;\n",
    "2. Features have different ranges of values, from very small range of continuous values - `age`, to very big ranges - `DebtRation` etc., which can impact gradient-based or distance-based Machine Learning Models, such as Logistic Regression or K-Nearest Neighbors;\n",
    "3. There might be present a considerable amount of outliers, judging by the percentile values for several columns, such as: `ResolvingUtilizationOfUnsecuredLines` or `DebtRation`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "912ae6b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "credit_train_zip_eda.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e7ca520",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_values_cols: list[str] = credit_train_zip_eda.isnull().sum()[credit_train_zip_eda.isnull().sum() > 0].index.tolist()\n",
    "missing_values_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf024407",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in missing_values_cols:\n",
    "    print(f\"Feature '{col}': {credit_train_zip_eda[col].isnull().sum()} missing values ({(credit_train_zip_eda[col].isnull().sum() / credit_train_zip_eda.shape[0] * 100):.2f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e6c7ade",
   "metadata": {},
   "source": [
    "There is a significant amount of missing values in `MonthlyIncome` column $\\approx 19.82\\%$, which is almost a fifth of the entire training set. In order to understand better how to treat those values, EDA should be performed to understand its distribution. On the other hand, column `NumberOfDependents` has a lower amount of missing values, $\\approx 2.62\\%$ which offers the possibility to drop those rows or use simple imputation mechanisms to treat them accordingly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f5c6f2a",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eca61a1d",
   "metadata": {},
   "source": [
    "In order to be able to explore and visualize data was used training set offered from Kaggle competition, in which null values were dropped in order to avoid problems at plotting the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21b793d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "credit_train_zip_eda = credit_train_zip_eda.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab15f39e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=2, ncols=1, figsize=(10, 8))\n",
    "\n",
    "sns.countplot(data=credit_train_zip_eda, x='SeriousDlqin2yrs', ax=axes[0])\n",
    "axes[0].set_title('Distribution of Serious Delinquency in Training Set')\n",
    "axes[0].set_xlabel('Serious Delinquency (1 = Yes, 0 = No)')\n",
    "axes[0].set_ylabel('Count')\n",
    "\n",
    "axes[1].pie(\n",
    "    credit_train_zip_eda['SeriousDlqin2yrs'].value_counts(),\n",
    "    autopct='%1.1f%%',\n",
    "    labels=['No Serious Delinquency', 'Serious Delinquency']\n",
    ")\n",
    "axes[1].set_title('Pie Chart of Serious Delinquency in Training Set')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1ecf4c5",
   "metadata": {},
   "source": [
    "As it was mentioned previously and now proven, the dataset is highly imbalanced, therefore imbalance mitigation techniques should be applied. Further in the notebook will be presented several techniques to help with this issue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80b4d136",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(10, 5))\n",
    "\n",
    "sns.histplot(\n",
    "    data=credit_train_zip_eda,\n",
    "    x='age',\n",
    "    bins=30,\n",
    "    kde=True,\n",
    "    ax=ax\n",
    ")\n",
    "ax.set_title('Age Distribution in Training Set')\n",
    "ax.set_xlabel('Age')\n",
    "ax.set_ylabel('Frequency')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b90d1780",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(10, 5))\n",
    "\n",
    "sns.boxplot(\n",
    "    data=credit_train_zip_eda,\n",
    "    x='age',\n",
    "    ax=ax\n",
    ")\n",
    "ax.set_title('Age Distribution in Training Set')\n",
    "ax.set_xlabel('Age')\n",
    "ax.set_ylabel('Frequency')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df02b24d",
   "metadata": {},
   "source": [
    "Column `age` is very close to the normal distribution, with several outlier points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ef7e17b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_outliers_by_boxplot(df: pd.DataFrame, column: str) -> pd.Series:\n",
    "    Q1 = df[column].quantile(0.25)\n",
    "    Q3 = df[column].quantile(0.75)\n",
    "    \n",
    "    IQR = Q3 - Q1\n",
    "    \n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    \n",
    "    outliers_mask = (df[column] < lower_bound) | (df[column] > upper_bound)\n",
    "    outliers_mask = outliers_mask.apply(\n",
    "        lambda x: -1 if x else 1\n",
    "    )\n",
    "\n",
    "    return outliers_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47383809",
   "metadata": {},
   "outputs": [],
   "source": [
    "outliers_age_mask = get_outliers_by_boxplot(credit_train_zip_eda, 'age')\n",
    "print(f\"Total Number of Samples: {credit_train_zip_eda.shape[0]}\")\n",
    "print(f\"Number of Outliers in Age Column detected using Boxplot Method: {outliers_age_mask[outliers_age_mask == -1].count()}\")\n",
    "print(f\"Number of Inliers in Age Column detected using Boxplot Method: {outliers_age_mask[outliers_age_mask == 1].count()}\")\n",
    "print(f\"Percentage of Outliers in Age Column detected using Boxplot Method: {(credit_train_zip_eda[outliers_age_mask == -1].shape[0] / credit_train_zip_eda.shape[0] * 100):.5f}%\")\n",
    "print(f\"Percentage of Inliers in Age Column detected using Boxplot Method: {(credit_train_zip_eda[outliers_age_mask == 1].shape[0] / credit_train_zip_eda.shape[0] * 100):.5f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7824427d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(10, 5))\n",
    "\n",
    "sns.boxplot(\n",
    "    data=credit_train_zip_eda[outliers_age_mask == 1],\n",
    "    x='age',\n",
    "    ax=ax\n",
    ")\n",
    "ax.set_title('Age Distribution in Training Set')\n",
    "ax.set_xlabel('Age')\n",
    "ax.set_ylabel('Frequency')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "295da8fa",
   "metadata": {},
   "source": [
    "It looks better now, no outliers remained, but the effect of this modification should be analyzed further in the model training process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bf4dd1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(10, 5))\n",
    "\n",
    "sns.boxplot(\n",
    "    data=credit_train_zip_eda,\n",
    "    x='MonthlyIncome',\n",
    "    ax=ax\n",
    ")\n",
    "ax.set_title('Monthly Income Distribution in Training Set')\n",
    "ax.set_xlabel('Monthly Income')\n",
    "ax.set_ylabel('Frequency')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "047d35c6",
   "metadata": {},
   "source": [
    "As it may be noticed, the boxplot of `MonthlyIncome` displays a lot of outlier points. This may be a sign that Monthly Income is adhering to a Non-Normal Distribution, therefore should be treated different. However, this does not mean that this column does not contain any outliers at all or does not adhere to Normal Distribution, but a very skewed one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cae187c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(10, 5))\n",
    "\n",
    "sns.histplot(\n",
    "    data=credit_train_zip_eda[credit_train_zip_eda['MonthlyIncome'] < 5e4],\n",
    "    x='MonthlyIncome',\n",
    "    bins=100,\n",
    "    ax=ax\n",
    ")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "420d8aec",
   "metadata": {},
   "source": [
    "As it may be seen, a subset of the `MonthlyIncome` column was selected, since, judging by the boxplot, the most values are under $5\\cdot10^4$ Monthly Income. This curve is very close to Gamma Curve. As a solution to bring this feature to a Normal Distribution is to apply Log Transformation. Thus, the data is brought to a Gaussian Distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06c9c103",
   "metadata": {},
   "outputs": [],
   "source": [
    "credit_train_zip_eda['MonthlyIncome'] = np.log1p(credit_train_zip['MonthlyIncome'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1607bc02",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(10, 5))\n",
    "\n",
    "sns.histplot(\n",
    "    data=credit_train_zip_eda,\n",
    "    x='MonthlyIncome',\n",
    "    bins=100,\n",
    "    ax=ax\n",
    ")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59b37940",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(10, 5))\n",
    "\n",
    "sns.boxplot(\n",
    "    data=credit_train_zip_eda,\n",
    "    x='MonthlyIncome',\n",
    "    ax=ax\n",
    ")\n",
    "ax.set_title('Monthly Income Distribution in Training Set')\n",
    "ax.set_xlabel('Monthly Income')\n",
    "ax.set_ylabel('Frequency')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3de1d73",
   "metadata": {},
   "source": [
    "After Log Transformation, `MonthlyIncome` column got closer to Normal Distribution. However, it finds a large amount of outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2406a97",
   "metadata": {},
   "outputs": [],
   "source": [
    "outliers_income_mask = get_outliers_by_boxplot(credit_train_zip_eda, 'MonthlyIncome')\n",
    "print(f\"Total Number of Samples: {credit_train_zip_eda.shape[0]}\")\n",
    "print(f\"Number of Outliers in Age Column detected using Boxplot Method: {outliers_income_mask[outliers_income_mask == -1].count()}\")\n",
    "print(f\"Number of Inliers in Age Column detected using Boxplot Method: {outliers_income_mask[outliers_income_mask == 1].count()}\")\n",
    "print(f\"Percentage of Outliers in Age Column detected using Boxplot Method: {(credit_train_zip_eda[outliers_income_mask == -1].shape[0] / credit_train_zip_eda.shape[0] * 100):.5f}%\")\n",
    "print(f\"Percentage of Inliers in Age Column detected using Boxplot Method: {(credit_train_zip_eda[outliers_income_mask == 1].shape[0] / credit_train_zip_eda.shape[0] * 100):.5f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "350569c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(10, 5))\n",
    "\n",
    "sns.boxplot(\n",
    "    data=credit_train_zip_eda[outliers_income_mask == 1],\n",
    "    x='MonthlyIncome',\n",
    "    ax=ax\n",
    ")\n",
    "ax.set_title('Monthly Income Distribution in Training Set')\n",
    "ax.set_xlabel('Monthly Income')\n",
    "ax.set_ylabel('Frequency')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e7b2e78",
   "metadata": {},
   "outputs": [],
   "source": [
    "outlier_detector = IsolationForest(\n",
    "    contamination=0.05,\n",
    "    random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "485fdfe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "outlier_detector.fit(credit_train_zip_eda[['MonthlyIncome']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c205c32",
   "metadata": {},
   "outputs": [],
   "source": [
    "outliers_series = outlier_detector.predict(credit_train_zip_eda[['MonthlyIncome']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3afe445",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(10, 5))\n",
    "\n",
    "sns.boxplot(\n",
    "    data=credit_train_zip_eda[outliers_series == 1],\n",
    "    x='age',\n",
    "    ax=ax\n",
    ")\n",
    "ax.set_title('Monthly Income Distribution in Training Set')\n",
    "ax.set_xlabel('Monthly Income')\n",
    "ax.set_ylabel('Frequency')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96d3d72b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Total Number of Samples: {credit_train_zip_eda.shape[0]}\")\n",
    "print(f\"Number of Outliers in MonthlyIncome Column detected using Isolation Forest Method: {np.sum(outliers_series == -1)}\")\n",
    "print(f\"Number of Inliers in MonthlyIncome Column detected using Isolation Forest Method: {np.sum(outliers_series == 1)}\")\n",
    "print(f\"Percentage of Outliers in MonthlyIncome Column detected using Isolation Forest Method: {(credit_train_zip_eda[outliers_series == -1].shape[0] / credit_train_zip_eda.shape[0] * 100):.5f}%\")\n",
    "print(f\"Percentage of Inliers in MonthlyIncome Column detected using Isolation Forest Method: {(credit_train_zip_eda[outliers_series == 1].shape[0] / credit_train_zip_eda.shape[0] * 100):.5f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb326550",
   "metadata": {},
   "source": [
    "In both implementations of Outlier Remvoal, this feature looks better now, but since the dataset is highly imbalanced, $\\approx 3.5%$ from Boxplot Method and $\\approx 4.7%$ from Isolation Forest of the `MonthlyIncome` samples is quite big. A solution is to flag potential outliers and create a new feature that will comprise the far points of very low and very high `MonthlyIncome` instead of just dropping them, since they might be a result of natural variance from original scale of values and, respectivelly, have an impact on the target variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "125fd88b",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_age = credit_train_zip_eda['age'].min()\n",
    "max_age = credit_train_zip_eda['age'].max()\n",
    "\n",
    "age_bins = [min_age, 10, 20, 30, 40, 50, 60, 70, 80, 90, 100, max_age]\n",
    "age_labels = [f'{min_age}-10', '11-20', '21-30', '31-40', '41-50', '51-60', '61-70', '71-80', '81-90', '91-100', f'101-{max_age}']\n",
    "\n",
    "age_binned = pd.cut(credit_train_zip_eda[outliers_income_mask == 1]['age'], bins=age_bins, labels=age_labels, include_lowest=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3fca906",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=2, ncols=1, figsize=(10, 5))\n",
    "\n",
    "sns.barplot(\n",
    "    x=age_binned,\n",
    "    y=np.expm1(credit_train_zip_eda[outliers_income_mask == 1]['MonthlyIncome']),\n",
    "    ax=axes[0]\n",
    ")\n",
    "axes[0].set_title('Monthly Income vs Age in Training Set')\n",
    "axes[0].set_xlabel('Age')\n",
    "axes[0].set_ylabel('Monthly Income')\n",
    "\n",
    "sns.countplot(\n",
    "    x=age_binned,\n",
    "    ax=axes[1]\n",
    ")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e01d52d7",
   "metadata": {},
   "source": [
    "As it may be seen, highest amount of monthly income is achieved by people in between 41 and 70 years old. At the same time, the highest count of the people are in between the same range of age. Besides that, lowest income is presented by people from 21-30 years old and 90+ years old. However, since 90+ years old people count is very low, their income may be not very suggestive, due to the low variance in these specific age groups. Also, there is some anomaly in the dataset - there is or are multiple samples of people in between 0 and 10 years old with a high income. Since no error bar is displayed, there might be a single record within that age group, which, again, is not representative and is most probably noise. As a conclusion, middle age people are the persons that earn the highest amount of money monthly, while young adults and old people have on average lower income."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "331658c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "credit_train_zip_eda['EstimatedMonthlyDebt'] = np.expm1(credit_train_zip_eda[outliers_income_mask == 1]['MonthlyIncome']) * credit_train_zip_eda[outliers_income_mask == 1]['DebtRatio']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "012d0bd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=2, ncols=1, figsize=(10, 5))\n",
    "\n",
    "sns.barplot(\n",
    "    x=age_binned,\n",
    "    y=credit_train_zip_eda['EstimatedMonthlyDebt'],\n",
    "    ax=axes[0]\n",
    ")\n",
    "axes[0].set_title('Estimated Monthly Debt (DebtRatio * MonthlyIncome) vs Age in Training Set')\n",
    "axes[0].set_xlabel('Age')\n",
    "axes[0].set_ylabel('Estimated Monthly Debt')\n",
    "\n",
    "sns.countplot(\n",
    "    x=age_binned,\n",
    "    ax=axes[1]\n",
    ")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ff812eb",
   "metadata": {},
   "source": [
    "Since `DebtRatio` represents borrowers monthly debt payments, living costs and alimony divided by their monthly gross income, from the reversed operation (`MonthlyIncome` $\\cdot$ `DebtRatio`), may be estimated their monthly debt payment amount. As it may be noticed, similar as in previous case, the age group with highest amount of monthly debt are the people of middle age, between 41 and 70 years old, and people with lowest month debt are people of adult young age and old people. Therefore, there might be a direct proportioanl relationship between the monthly income and monthly debt, which is reasonable, since on average, people will borrow money if they have the finances to return them back."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abe8d459",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(10, 5))\n",
    "\n",
    "sns.violinplot(\n",
    "    x=credit_train_zip_eda[np.expm1(credit_train_zip_eda['MonthlyIncome']) < 5e4]['SeriousDlqin2yrs'],\n",
    "    y=np.expm1(credit_train_zip_eda[np.expm1(credit_train_zip_eda['MonthlyIncome']) < 5e4]['MonthlyIncome']),\n",
    "    hue=credit_train_zip_eda[np.expm1(credit_train_zip_eda['MonthlyIncome']) < 5e4]['SeriousDlqin2yrs'],\n",
    "    ax=ax\n",
    ")\n",
    "ax.set_title('Serious Delinquency vs Monthly Income in Training Set')\n",
    "ax.set_xlabel('Serious Delinquency (0 = No, 1 = Yes)')\n",
    "ax.set_ylabel('Monthly Income')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91b0d52e",
   "metadata": {},
   "source": [
    "As it may be noticed, on the reduced training set, there is no significant difference in whether people encountered serious delinquency in the past 2 years, based on their monthly income. However, people with less income were slightly higher rate of encountering delinquency in the past 2 years than people with higher monthly income. Remembering the fact that this dataset is heavily imbalanced, this may not be very conclusive, since there are considerably less records about people that are in the possitive class of the target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04a9c391",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(10, 5))\n",
    "\n",
    "sns.histplot(\n",
    "    data=credit_train_zip_eda,\n",
    "    x='DebtRatio',\n",
    "    bins=30,\n",
    "    ax=ax\n",
    ")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43fc64fb",
   "metadata": {},
   "source": [
    "As it may be noticed, the histogram of the `DebtRatio` is inconclusive, due to the presence of outliers. In previous section was mentioned that `DebtRatio` at 75 percentile is present the value $\\approx 0.87$, while maximum is $329664$, which obviously skews this feature. Therefore, this feature will cut to properly visualize it. Arbitrarily was selected value $2$ to exclude higher Debt Ratios from the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e5b89cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "(credit_train_zip_eda['DebtRatio'] > 2).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e74e4a84",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(10, 5))\n",
    "\n",
    "sns.boxplot(\n",
    "    x=credit_train_zip_eda[credit_train_zip_eda['DebtRatio'] < 2]['SeriousDlqin2yrs'],\n",
    "    y=credit_train_zip_eda[credit_train_zip_eda['DebtRatio'] < 2]['DebtRatio'],\n",
    "    hue=credit_train_zip_eda[credit_train_zip_eda['DebtRatio'] < 2]['SeriousDlqin2yrs'],\n",
    "    ax=ax\n",
    ")\n",
    "ax.set_title('Serious Delinquency vs Debt Ratio in Training Set')\n",
    "ax.set_xlabel('Serious Delinquency (0 = No, 1 = Yes)')\n",
    "ax.set_ylabel('Debt Ratio')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76917ca7",
   "metadata": {},
   "source": [
    "As a result, people with higher Debt Ratio are slightly likely to experience 90 days past due delinquency, since the higher debt ratio means bigger difference between the total amount of monthly debt payments and their monthly income, making them less capable of properly paying back in time. People that were severily over due have an average Debt Ratio higher than $\\approx 0.35$, while people with no serious delinquency - $\\approx 0.27$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fc9a6f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(10, 5))\n",
    "\n",
    "sns.histplot(\n",
    "    data=credit_train_zip_eda,\n",
    "    x='RevolvingUtilizationOfUnsecuredLines',\n",
    "    bins=100,\n",
    "    ax=ax\n",
    ")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dca47b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "(credit_train_zip_eda['RevolvingUtilizationOfUnsecuredLines'] > 2).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5c3fcf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(10, 5))\n",
    "\n",
    "sns.boxplot(\n",
    "    x=credit_train_zip_eda[credit_train_zip_eda['RevolvingUtilizationOfUnsecuredLines'] < 2]['SeriousDlqin2yrs'],\n",
    "    y=credit_train_zip_eda[credit_train_zip_eda['RevolvingUtilizationOfUnsecuredLines'] < 2]['RevolvingUtilizationOfUnsecuredLines'],\n",
    "    hue=credit_train_zip_eda[credit_train_zip_eda['RevolvingUtilizationOfUnsecuredLines'] < 2]['SeriousDlqin2yrs'],\n",
    "    ax=ax\n",
    ")\n",
    "ax.set_title('Serious Delinquency vs Revolving Utilization Of Unsecured Lines in Training Set')\n",
    "ax.set_xlabel('Serious Delinquency (0 = No, 1 = Yes)')\n",
    "ax.set_ylabel('Revolving Utilization Of Unsecured Lines')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "496ca042",
   "metadata": {},
   "source": [
    "Revolving Utilization of Unsecured Lines in this dataset refers to the ratio between the total balance on credit cards and total credit limits. In other words, if borrower spents all the money that banks landed them, the Revolving Utilization will be equal to $1$, making them less trustworthy from the perspective of banks, since they uses all the money they borrowed, and it makes them less capable of paying back. As expected, persons with higher percentage are significantly inclined to experience delinquency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59cc5bfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(10, 5))\n",
    "\n",
    "sns.countplot(\n",
    "    x=credit_train_zip_eda['NumberOfDependents'],\n",
    "    ax=ax\n",
    ")\n",
    "ax.set_title('Distribution of Number of Dependents in Training Set')\n",
    "ax.set_ylabel('NumberOfDependents')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee14d0f5",
   "metadata": {},
   "source": [
    "Most borrowers have no dependents or at least 1 dependent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8ff4036",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(10, 5))\n",
    "\n",
    "sns.countplot(\n",
    "    x=np.where(credit_train_zip_eda['NumberOfDependents'] == 0, 'No Dependents', 'Has Dependents'),\n",
    "    hue=np.where(credit_train_zip_eda['NumberOfDependents'] == 0, 'No Dependents', 'Has Dependents'),\n",
    "    ax=ax\n",
    ")\n",
    "ax.set_title('Distribution of Number of Dependents in Training Set')\n",
    "ax.set_xlabel('NumberOfDependents')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86df2752",
   "metadata": {},
   "source": [
    "In the above plot is represented the count plot of borrowers with no dependents, in other words - family members or people that rely on financial support of the borrower, and people with at least one dependent. All categories combined together are still slightly less than people with no dependents, but is now more comparable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29fa53b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=2, ncols=1, figsize=(10, 5))\n",
    "\n",
    "sns.barplot(\n",
    "    x=credit_train_zip_eda[outliers_income_mask == 1]['NumberOfDependents'],\n",
    "    y=np.expm1(credit_train_zip_eda[outliers_income_mask == 1]['MonthlyIncome']),\n",
    "    ax=axes[0]\n",
    ")\n",
    "axes[0].set_title('Monthly Income vs Number of Dependents in Training Set')\n",
    "axes[0].set_xlabel('Number of Dependents')\n",
    "axes[0].set_ylabel('Monthly Income')\n",
    "\n",
    "sns.countplot(\n",
    "    x=credit_train_zip_eda[outliers_income_mask == 1]['NumberOfDependents'],\n",
    "    ax=axes[1]\n",
    ")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ea83eac",
   "metadata": {},
   "source": [
    "As it may be noticed, higher number of dependents results in higher monthly income, which is logic since more money is needed to support family and other dependents. However, there are small numbers of samples with borrowers with more than 3 dependents, therefore their monthly income is not precise and holds little variance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8400d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=2, ncols=1, figsize=(10, 5))\n",
    "\n",
    "sns.barplot(\n",
    "    x=np.where(credit_train_zip_eda[outliers_income_mask == 1]['NumberOfDependents'] == 0, 'No Dependents', 'Has Dependents'),\n",
    "    y=np.expm1(credit_train_zip_eda[outliers_income_mask == 1]['MonthlyIncome']),\n",
    "    hue=np.where(credit_train_zip_eda[outliers_income_mask == 1]['NumberOfDependents'] == 0, 'No Dependents', 'Has Dependents'),\n",
    "    ax=axes[0]\n",
    ")\n",
    "axes[0].set_title('Monthly Income vs Number of Dependents in Training Set')\n",
    "axes[0].set_xlabel('Number of Dependents')\n",
    "axes[0].set_ylabel('Monthly Income')\n",
    "\n",
    "sns.countplot(\n",
    "    x=np.where(credit_train_zip_eda[outliers_income_mask == 1]['NumberOfDependents'] == 0, 'No Dependents', 'Has Dependents'),\n",
    "    hue=np.where(credit_train_zip_eda[outliers_income_mask == 1]['NumberOfDependents'] == 0, 'No Dependents', 'Has Dependents'),\n",
    "    ax=axes[1]\n",
    ")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff6f1640",
   "metadata": {},
   "source": [
    "As a result of aggregation, borrowers with no dependents, on average, have lower monthly income than people with at least one dependent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba3e731e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=2, ncols=1, figsize=(10, 5))\n",
    "\n",
    "sns.barplot(\n",
    "    x=np.where(credit_train_zip_eda[outliers_income_mask == 1]['NumberOfDependents'] == 0, 'No Dependents', 'Has Dependents'),\n",
    "    y=np.expm1(credit_train_zip_eda[outliers_income_mask == 1]['MonthlyIncome']),\n",
    "    hue=credit_train_zip_eda[outliers_income_mask == 1]['SeriousDlqin2yrs'],\n",
    "    ax=axes[0]\n",
    ")\n",
    "axes[0].set_title('Monthly Income vs Number of Dependents in Training Set')\n",
    "axes[0].set_xlabel('Number of Dependents')\n",
    "axes[0].set_ylabel('Monthly Income')\n",
    "\n",
    "sns.countplot(\n",
    "    x=np.where(credit_train_zip_eda[outliers_income_mask == 1]['NumberOfDependents'] == 0, 'No Dependents', 'Has Dependents'),\n",
    "    hue=credit_train_zip_eda[outliers_income_mask == 1]['SeriousDlqin2yrs'],\n",
    "    ax=axes[1]\n",
    ")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6943f1a2",
   "metadata": {},
   "source": [
    "From the plot above may be derived that borrowers with at least one dependent and encountered delinquency has considerably lower monthly income that borrowers with one or more dependents and no delinquency. Similar trend is observed in the group of borrowers with no dependents at all."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ce0f80e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(10, 5))\n",
    "\n",
    "sns.boxplot(\n",
    "    x=credit_train_zip_eda['SeriousDlqin2yrs'],\n",
    "    y=credit_train_zip_eda['NumberOfOpenCreditLinesAndLoans'],\n",
    "    hue=credit_train_zip_eda['SeriousDlqin2yrs'],\n",
    "    ax=ax\n",
    ")\n",
    "ax.set_title('Serious Delinquency vs Number of Open Credit Lines And Loans in Training Set')\n",
    "ax.set_xlabel('Serious Delinquency (0 = No, 1 = Yes)')\n",
    "ax.set_ylabel('Number of Open Credit Lines And Loans')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdcbd218",
   "metadata": {},
   "source": [
    "No noticeable difference between the number of open credit lines and loans between borrowers that encountered serious delinquence and those who did not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5811d89f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=2, ncols=1, figsize=(10, 5))\n",
    "\n",
    "sns.lineplot(\n",
    "    x=credit_train_zip_eda[outliers_income_mask == 1]['NumberOfOpenCreditLinesAndLoans'],\n",
    "    y=np.expm1(credit_train_zip_eda[outliers_income_mask == 1]['MonthlyIncome']) * credit_train_zip_eda[outliers_income_mask == 1]['DebtRatio'],\n",
    "    hue=credit_train_zip_eda[outliers_income_mask == 1]['SeriousDlqin2yrs'],\n",
    "    ax=axes[0]\n",
    ")\n",
    "axes[0].set_title('Estimated Monthly Debt (DebtRatio * MonthlyIncome) vs Number of Open Credit Lines And Loans in Training Set')\n",
    "axes[0].set_xlabel('Number of Open Credit Lines And Loans')\n",
    "axes[0].set_ylabel('Estimated Monthly Debt')\n",
    "\n",
    "sns.countplot(\n",
    "    x=credit_train_zip_eda[outliers_income_mask == 1]['NumberOfOpenCreditLinesAndLoans'],\n",
    "    hue=credit_train_zip_eda[outliers_income_mask == 1]['SeriousDlqin2yrs'],\n",
    "    ax=axes[1]\n",
    ")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aef767fa",
   "metadata": {},
   "source": [
    "As it may be observed, on average, borrowers have from 3 to 9 open credit lines and loans. Also, higher number of open loans results in higher estimated monthly debt. In the category of higher count of samples is distinguished slightly higher monthly debt for people that encountered serious delinquency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "860db947",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(10, 5))\n",
    "\n",
    "sns.boxplot(\n",
    "    x=credit_train_zip_eda['SeriousDlqin2yrs'],\n",
    "    y=credit_train_zip_eda['NumberRealEstateLoansOrLines'],\n",
    "    hue=credit_train_zip_eda['SeriousDlqin2yrs'],\n",
    "    ax=ax\n",
    ")\n",
    "ax.set_title('Serious Delinquency vs Number of Real Estate Loans Or Lines in Training Set')\n",
    "ax.set_xlabel('Serious Delinquency (0 = No, 1 = Yes)')\n",
    "ax.set_ylabel('Number of Open Credit Lines And Loans')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38f1742c",
   "metadata": {},
   "source": [
    "Again, no significant difference in the distributions of Number of Real Estate Loans Or Lines between borrowers that manifeste delinquency and those who did not, which may be a result "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adcac4d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=2, ncols=1, figsize=(10, 5))\n",
    "\n",
    "sns.lineplot(\n",
    "    x=credit_train_zip_eda[outliers_income_mask == 1]['NumberRealEstateLoansOrLines'],\n",
    "    y=credit_train_zip_eda['EstimatedMonthlyDebt'],\n",
    "    hue=credit_train_zip_eda[outliers_income_mask == 1]['SeriousDlqin2yrs'],\n",
    "    ax=axes[0]\n",
    ")\n",
    "axes[0].set_title('Estimated Monthly Debt (DebtRatio * MonthlyIncome) vs Number of Real Estate Loans Or Lines in Training Set')\n",
    "axes[0].set_xlabel('Number of Open Credit Lines And Loans')\n",
    "axes[0].set_ylabel('Estimated Monthly Debt')\n",
    "\n",
    "sns.countplot(\n",
    "    x=credit_train_zip_eda[outliers_income_mask == 1]['NumberRealEstateLoansOrLines'],\n",
    "    hue=credit_train_zip_eda[outliers_income_mask == 1]['SeriousDlqin2yrs'],\n",
    "    ax=axes[1]\n",
    ")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16940eb7",
   "metadata": {},
   "source": [
    "As it may be noticed, higher number of open credit lines and loans results in higher monthly debt. Since there are very few positive target samples, it may be inconclusive. However, there is no significant difference between the monthly debt based on the number of real estate loans."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a247177",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=2, ncols=1, figsize=(10, 5))\n",
    "\n",
    "sns.lineplot(\n",
    "    x=credit_train_zip_eda[outliers_income_mask == 1]['NumberRealEstateLoansOrLines'],\n",
    "    y=np.expm1(credit_train_zip_eda[outliers_income_mask == 1]['MonthlyIncome']),\n",
    "    hue=credit_train_zip_eda[outliers_income_mask == 1]['SeriousDlqin2yrs'],\n",
    "    ax=axes[0]\n",
    ")\n",
    "axes[0].set_title('Monthly Income vs Number of Real Estate Loans Or Lines in Training Set')\n",
    "axes[0].set_xlabel('Number of Open Credit Lines And Loans')\n",
    "axes[0].set_ylabel('Monthly Income')\n",
    "\n",
    "sns.countplot(\n",
    "    x=credit_train_zip_eda[outliers_income_mask == 1]['NumberRealEstateLoansOrLines'],\n",
    "    hue=credit_train_zip_eda[outliers_income_mask == 1]['SeriousDlqin2yrs'],\n",
    "    ax=axes[1]\n",
    ")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0705e826",
   "metadata": {},
   "source": [
    "If plotted against the monthly income, there is a difference between borrowers with delinquency and without - those who manifeste serious delinquency had lower monthly income than those who did not manifested serious violations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01bcb89a",
   "metadata": {},
   "outputs": [],
   "source": [
    "credit_train_zip_eda['TotalNumberOfTimePastDue'] = credit_train_zip_eda['NumberOfTime30-59DaysPastDueNotWorse'] + credit_train_zip_eda['NumberOfTime60-89DaysPastDueNotWorse'] + credit_train_zip_eda['NumberOfTimes90DaysLate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "372237fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=2, ncols=1, figsize=(10, 5))\n",
    "\n",
    "sns.barplot(\n",
    "    x=credit_train_zip_eda['SeriousDlqin2yrs'],\n",
    "    y=credit_train_zip_eda['TotalNumberOfTimePastDue'],\n",
    "    hue=credit_train_zip_eda['SeriousDlqin2yrs'],\n",
    "    ax=axes[0]\n",
    ")\n",
    "axes[0].set_title('Total Number of Times Past Due vs Serious Delinquency in Training Set')\n",
    "axes[0].set_xlabel('Serious Delinquency (0 = No, 1 = Yes)')\n",
    "axes[0].set_ylabel('Total Number of Times Past Due')\n",
    "\n",
    "sns.countplot(\n",
    "    x=credit_train_zip_eda['TotalNumberOfTimePastDue'],\n",
    "    hue=credit_train_zip_eda['SeriousDlqin2yrs'],\n",
    "    ax=axes[1]\n",
    ")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a9f61b3",
   "metadata": {},
   "source": [
    "As it may be noticed, most people that encountered delinquency were past due with payback a lot more than borrowers that did not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "487a4234",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=2, ncols=1, figsize=(10, 5))\n",
    "\n",
    "sns.lineplot(\n",
    "    x=credit_train_zip_eda[(outliers_income_mask == 1) & (credit_train_zip_eda['TotalNumberOfTimePastDue'] < 20)]['TotalNumberOfTimePastDue'],\n",
    "    y=np.expm1(credit_train_zip_eda[(outliers_income_mask == 1) & (credit_train_zip_eda['TotalNumberOfTimePastDue'] < 20)]['MonthlyIncome']),\n",
    "    hue=credit_train_zip_eda[(outliers_income_mask == 1) & (credit_train_zip_eda['TotalNumberOfTimePastDue'] < 20)]['SeriousDlqin2yrs'],\n",
    "    ax=axes[0]\n",
    ")\n",
    "axes[0].set_title('Total Number of Times Past Due vs Serious Delinquency in Training Set')\n",
    "axes[0].set_xlabel('Total Number of Times Past Due')\n",
    "axes[0].set_ylabel('Monthly Income')\n",
    "\n",
    "sns.countplot(\n",
    "    x=credit_train_zip_eda[(outliers_income_mask == 1) & (credit_train_zip_eda['TotalNumberOfTimePastDue'] < 20)]['TotalNumberOfTimePastDue'],\n",
    "    hue=credit_train_zip_eda[(outliers_income_mask == 1) & (credit_train_zip_eda['TotalNumberOfTimePastDue'] < 20)]['SeriousDlqin2yrs'],\n",
    "    ax=axes[1]\n",
    ")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64898d45",
   "metadata": {},
   "source": [
    "Also, on the average, people that borrowed money from the banks and had a higher monthly income did not experience delinquency like people that had lower income and were at the same number of days past due with their payback."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39912851",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(10, 5))\n",
    "\n",
    "sns.violinplot(\n",
    "    x=credit_train_zip_eda[(credit_train_zip_eda['RevolvingUtilizationOfUnsecuredLines'] < 2) & (credit_train_zip_eda['TotalNumberOfTimePastDue'] < 50)]['SeriousDlqin2yrs'],\n",
    "    y=credit_train_zip_eda[(credit_train_zip_eda['RevolvingUtilizationOfUnsecuredLines'] < 2) & (credit_train_zip_eda['TotalNumberOfTimePastDue'] < 50)]['TotalNumberOfTimePastDue'],\n",
    "    hue=credit_train_zip_eda[(credit_train_zip_eda['RevolvingUtilizationOfUnsecuredLines'] < 2) & (credit_train_zip_eda['TotalNumberOfTimePastDue'] < 50)]['SeriousDlqin2yrs'],\n",
    "    ax=ax\n",
    ")\n",
    "ax.set_title('Total Number of Times Past Due vs Serious Delinquency in Training Set')\n",
    "ax.set_xlabel('Serious Delinquency (0 = No, 1 = Yes)')\n",
    "ax.set_ylabel('Total Number of Times Past Due')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb5d2e75",
   "metadata": {},
   "source": [
    "Most people that were over due with their loans were more likely to manifest delinquency in the past 2 years, however, there are still people that manifested delinquency while having lower number of past due occurences, while people that did not encounter delinquency were mostly people with very low number of past due paybacks or even without them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50f05ad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(10, 5))\n",
    "\n",
    "sns.countplot(\n",
    "    x=credit_train_zip_eda['NumberOfTimes90DaysLate'],\n",
    "    hue=credit_train_zip_eda['SeriousDlqin2yrs'],\n",
    "    ax=ax\n",
    ")\n",
    "ax.set_title('Distribution of Borrowers that had overdue 90+ days in Training Set')\n",
    "ax.set_xlabel('Number of Times 90 Days Late')\n",
    "ax.set_ylabel('Count')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "872166ca",
   "metadata": {},
   "source": [
    "Most records capture borrowers that did not pass the 90 days past due period, however several counts of at least 1 occurence of 90+ day overdue was recorded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "924db0fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(10, 5))\n",
    "\n",
    "sns.countplot(\n",
    "    x=np.where(credit_train_zip_eda['NumberOfTimes90DaysLate'] == 0, 'No 90+ days overdue', '90+ days overdue'),\n",
    "    hue=credit_train_zip_eda['SeriousDlqin2yrs'],\n",
    "    ax=ax\n",
    ")\n",
    "ax.set_title('Distribution of Borrowers that had overdue 90+ days in Training Set')\n",
    "ax.set_xlabel('Number of Times 90 Days Late')\n",
    "ax.set_ylabel('Count')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ca9ce58",
   "metadata": {},
   "source": [
    "This feature is highly imbalanced. Taken in consideration that most people that did not encounter delinquency did not get past 90 days of not paying back, this number of people is greatly reduced in at least 1 occurence of that behavior, getting very close to the number of people that encountered delinquency and had at least one 90+ days overdue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c69f588c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(10, 5))\n",
    "\n",
    "sns.violinplot(\n",
    "    x=credit_train_zip_eda[credit_train_zip_eda['NumberOfTimes90DaysLate'] < 10]['SeriousDlqin2yrs'],\n",
    "    y=credit_train_zip_eda[credit_train_zip_eda['NumberOfTimes90DaysLate'] < 10]['NumberOfTimes90DaysLate'],\n",
    "    hue=credit_train_zip_eda[credit_train_zip_eda['NumberOfTimes90DaysLate'] < 10]['SeriousDlqin2yrs'],\n",
    "    ax=ax\n",
    ")\n",
    "ax.set_title('Borrowers that had overdue 90+ days vs Serious Delinquency in Training Set')\n",
    "ax.set_xlabel('Serious Delinquency (0 = No, 1 = Yes)')\n",
    "ax.set_ylabel('Total Number of Times Past Due')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "762d0dbb",
   "metadata": {},
   "source": [
    "Higher number of people that encountered delinquency had beed overdue 90+ days in comparison with the fewer number of people who did not manifest delinquency. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3464fdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(10, 5))\n",
    "\n",
    "sns.countplot(\n",
    "    x=credit_train_zip_eda['NumberOfTime60-89DaysPastDueNotWorse'],\n",
    "    hue=credit_train_zip_eda['SeriousDlqin2yrs'],\n",
    "    ax=ax\n",
    ")\n",
    "ax.set_title('Distribution of Borrowers that had overdue 60 to 89 days in Training Set')\n",
    "ax.set_xlabel('Number of Times 60 to 89 Days Late Paybacks')\n",
    "ax.set_ylabel('Count')\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cab8807",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(10, 5))\n",
    "\n",
    "sns.countplot(\n",
    "    x=np.where(credit_train_zip_eda['NumberOfTime60-89DaysPastDueNotWorse'] == 0, 'No 60-89 days overdue', '60-89 days overdue'),\n",
    "    hue=credit_train_zip_eda['SeriousDlqin2yrs'],\n",
    "    ax=ax\n",
    ")\n",
    "ax.set_title('Distribution of Borrowers that had overdure 60 to 89 days in Training Set')\n",
    "ax.set_xlabel('Number of Times 60 to 89 Days Late')\n",
    "ax.set_ylabel('Count')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6510fbaa",
   "metadata": {},
   "source": [
    "Similar relationship as in previous case with 90+ days overdue paybacks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6a6b56b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(10, 5))\n",
    "\n",
    "sns.violinplot(\n",
    "    x=credit_train_zip_eda[credit_train_zip_eda['NumberOfTime60-89DaysPastDueNotWorse'] < 10]['SeriousDlqin2yrs'],\n",
    "    y=credit_train_zip_eda[credit_train_zip_eda['NumberOfTime60-89DaysPastDueNotWorse'] < 10]['NumberOfTime60-89DaysPastDueNotWorse'],\n",
    "    hue=credit_train_zip_eda[credit_train_zip_eda['NumberOfTime60-89DaysPastDueNotWorse'] < 10]['SeriousDlqin2yrs'],\n",
    "    ax=ax\n",
    ")\n",
    "ax.set_title('Borrowers that had overdue 60 to 89 days vs Serious Delinquency in Training Set')\n",
    "ax.set_xlabel('Serious Delinquency (0 = No, 1 = Yes)')\n",
    "ax.set_ylabel('Total Number of Times Past Due')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "704b74f8",
   "metadata": {},
   "source": [
    "Slightly higher number of people that encountered delinquency had beed overdue 60 to 89 days in comparison with the fewer number of people who did not manifest delinquency in the same range of past due occasions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "367835fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(10, 5))\n",
    "\n",
    "sns.countplot(\n",
    "    x=credit_train_zip_eda['NumberOfTime30-59DaysPastDueNotWorse'],\n",
    "    hue=credit_train_zip_eda['SeriousDlqin2yrs'],\n",
    "    ax=ax\n",
    ")\n",
    "ax.set_title('Distribution of Borrowers that had overdure 30 to 59 days in Training Set')\n",
    "ax.set_xlabel('Number of Times 30 to 59 Days Late Paybacks')\n",
    "ax.set_ylabel('Count')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6380a52d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(10, 5))\n",
    "\n",
    "sns.countplot(\n",
    "    x=np.where(credit_train_zip_eda['NumberOfTime30-59DaysPastDueNotWorse'] == 0, 'No 30-59 days overdue', '30-59 days overdue'),\n",
    "    hue=credit_train_zip_eda['SeriousDlqin2yrs'],\n",
    "    ax=ax\n",
    ")\n",
    "ax.set_title('Distribution of Borrowers that had overdure 30 to 59 days in Training Set')\n",
    "ax.set_xlabel('Number of Times 30 to 59 Days Late')\n",
    "ax.set_ylabel('Count')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37e28673",
   "metadata": {},
   "source": [
    "Again, no significant difference than in previous cases of overdue. People that did not have overdue payments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b0d945f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(10, 5))\n",
    "\n",
    "sns.violinplot(\n",
    "    x=credit_train_zip_eda[credit_train_zip_eda['NumberOfTime30-59DaysPastDueNotWorse'] < 10]['SeriousDlqin2yrs'],\n",
    "    y=credit_train_zip_eda[credit_train_zip_eda['NumberOfTime30-59DaysPastDueNotWorse'] < 10]['NumberOfTime30-59DaysPastDueNotWorse'],\n",
    "    hue=credit_train_zip_eda[credit_train_zip_eda['NumberOfTime30-59DaysPastDueNotWorse'] < 10]['SeriousDlqin2yrs'],\n",
    "    ax=ax\n",
    ")\n",
    "ax.set_title('Borrowers that had overdue 30 to 59 days vs Serious Delinquency in Training Set')\n",
    "ax.set_xlabel('Serious Delinquency (0 = No, 1 = Yes)')\n",
    "ax.set_ylabel('Total Number of Times Past Due')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70bb3582",
   "metadata": {},
   "source": [
    "Significantly higher number of people that encountered delinquency had beed overdue 30 to 59 days in comparison with the fewer number of people who did not manifest delinquency in the same range of past due occasions. Also, many borrowers that had delinquency in the past 2 years had nmumerous past due paybacks, which decreases their credibility."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85eae635",
   "metadata": {},
   "source": [
    "### Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69e8361d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(credit_train_zip.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77c5383b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(credit_test_zip.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c18e7f27",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=2, ncols=1, figsize=(10, 8))\n",
    "\n",
    "sns.countplot(x=credit_train_zip['MonthlyIncome'].isnull(), \n",
    "              ax=axes[0],\n",
    "              hue=credit_train_zip['MonthlyIncome'].isnull()\n",
    "              )\n",
    "axes[0].set_title('Distribution of Monthly Income and Null Values in Training Set')\n",
    "axes[0].set_xlabel('Is Monthly Income NaN')\n",
    "axes[0].set_ylabel('Count')\n",
    "\n",
    "axes[1].pie(\n",
    "    credit_train_zip['MonthlyIncome'].isnull().value_counts(),\n",
    "    autopct='%1.1f%%',\n",
    ")\n",
    "axes[1].set_title('Pie Chart of Monthly Income and Null Values in Training Set')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cba677a0",
   "metadata": {},
   "source": [
    "Since there is a significant portion of the dataset with missing monthly income values, more advanced imputation techniques should be used in order to replace them with numerical values. One way to do that is to select a subset of features that may affect the monthly income of the borrower and train a model-based Imputation techniques, such as: K-Nearest Neighbosr Imputer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d21999c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=2, ncols=1, figsize=(10, 8))\n",
    "\n",
    "sns.countplot(x=credit_train_zip['NumberOfDependents'].isnull(), \n",
    "              ax=axes[0],\n",
    "              hue=credit_train_zip['NumberOfDependents'].isnull()\n",
    "              )\n",
    "axes[0].set_title('Distribution of Number of Dependents and Null Values in Training Set')\n",
    "axes[0].set_xlabel('Is Number of Dependents NaN')\n",
    "axes[0].set_ylabel('Count')\n",
    "\n",
    "axes[1].pie(\n",
    "    credit_train_zip['NumberOfDependents'].isnull().value_counts(),\n",
    "    autopct='%1.1f%%',\n",
    ")\n",
    "axes[1].set_title('Pie Chart of Number of Dependents and Null Values in Training Set')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7b416c5",
   "metadata": {},
   "source": [
    "There are not so many rows in `NumberOfDependents` column with missing values, therefore basic imputation technique may be used, such as: Median Imputation, since the distribution is skewed and there are no intermediate values, only integers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dad0a243",
   "metadata": {},
   "source": [
    "## Model Selection\n",
    "\n",
    "For the ML models that can be used, were analyzed the following options:\n",
    "1. **Random Forest Classifier**, since it is robust to outliers and does not require scaling of the features to be done;\n",
    "2. **XGBoost Classifier**, similar concept as Random Forest, but different implementation. It builds sequentially Decision Trees and each new tree corrects errors made by the previous ones. It is suitable when the dataset is large, as it is a fast algorithm, again - robust to outliers and feature scale;\n",
    "3. **LightGBM Classifier**, similar to XGBoost, with slightly different tree building mechanism, faster training time, but less likely to find a generalized model and is less robust to outliers and noise in dataset.\n",
    "3. **Logistic Regression** - the most basic classifier, fits the sigmoid function curve, offers fast computations and straight-forward interpretation of the results;\n",
    "4. **Support Vector Machine Classifier** - powerful ML Model, but it requires data be standardized, which expects the data adhere to Gaussian Distribution. However, as it was described above, not all features are following this distribution. Also, it is very computationally expensive even on small datasets and does not support parallelization by default.\n",
    "5. **K-Nearest Neighbors Classifier** - non-parametric (no assumption required for data distribution) algorithm with output being the class membership of a data point, based on the majority of type of its neighbors. Calculates the distance between each point, therefore is computationally intensive.\n",
    "\n",
    "Since the dataset is not very large, will be attempted to train all of the above models, except Support Vector Machine Classifier, since it still is very computationally expensive, even on small dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a06c036c",
   "metadata": {},
   "source": [
    "## Dataset Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "653a6add",
   "metadata": {},
   "source": [
    "1. `_zip` - only `cs-train.csv` is used, for local score determination, models are trained on a subset of the Kaggle training set;\n",
    "2. `_sub` - both `cs-train.csv` and `cs-test.csv` are used, for Kaggle submission of the predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed6b4755",
   "metadata": {},
   "outputs": [],
   "source": [
    "credit_train_zip: pd.DataFrame = pd.read_csv(filepath_or_buffer='dataset/cs-training.csv', sep=',')\n",
    "credit_test_zip: pd.DataFrame = pd.read_csv(filepath_or_buffer='dataset/cs-test.csv', sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fd685ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "credit_train_zip_X: pd.DataFrame = credit_train_zip.drop(columns=['SeriousDlqin2yrs'])\n",
    "credit_train_zip_y: pd.Series = credit_train_zip['SeriousDlqin2yrs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "304b3e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_zip, X_test_zip, y_train_zip, y_test_zip = train_test_split(\n",
    "    credit_train_zip_X,\n",
    "    credit_train_zip_y,\n",
    "    test_size=0.2,\n",
    "    random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2937d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_sub: pd.DataFrame = credit_train_zip.drop(columns=['SeriousDlqin2yrs'])\n",
    "y_train_sub: pd.Series = credit_train_zip['SeriousDlqin2yrs']\n",
    "X_test_sub: pd.DataFrame = credit_test_zip.drop(columns=['SeriousDlqin2yrs'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e080cbda",
   "metadata": {},
   "source": [
    "## Utils - General"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a00ea907",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_roc_curve_from_probabilities(y_true: np.ndarray, y_prob_pred: np.ndarray, estimator_name: str = None) -> None:\n",
    "    fpr, tpr, _ = roc_curve(y_true=y_true, y_score=y_prob_pred, drop_intermediate=False)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    display = RocCurveDisplay(\n",
    "        fpr=fpr,\n",
    "        tpr=tpr,\n",
    "        roc_auc=roc_auc,\n",
    "        estimator_name=estimator_name if estimator_name is not None else estimator_name.__class__.__name__\n",
    "    )\n",
    "    \n",
    "    display.plot()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44fdaef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_roc_curve_from_estimator(X: pd.DataFrame | np.ndarray, y: pd.Series | np.ndarray, estimator: BaseEstimator, estimator_name: str = None) -> None:\n",
    "    RocCurveDisplay.from_estimator(\n",
    "        estimator=estimator, \n",
    "        X=X, \n",
    "        y=y,\n",
    "        name=estimator_name if estimator_name is not None else estimator.__class__.__name__\n",
    "    )\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ebf0252",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_precision_recall_curve_from_probabilities(y_true: np.ndarray, y_prob_pred: np.ndarray, pos_label: int = 1, estimator_name: str = None) -> None:\n",
    "    precision, recall, _ = precision_recall_curve(y_true=y_true, y_score=y_prob_pred, pos_label=pos_label)\n",
    "    display = RocCurveDisplay(\n",
    "        precision=precision,\n",
    "        recall=recall,\n",
    "        estimator_name=estimator_name if estimator_name is not None else estimator_name.__class__.__name__\n",
    "    )\n",
    "    \n",
    "    display.plot()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d8e64dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_precision_recall_curve_from_estimator(X: pd.DataFrame | np.ndarray, y: pd.Series | np.ndarray, estimator: BaseEstimator, estimator_name: str = None) -> None:\n",
    "    PrecisionRecallDisplay.from_estimator(\n",
    "        estimator=estimator, \n",
    "        X=X,\n",
    "        y=y,\n",
    "        name=estimator_name if estimator_name is not None else estimator.__class__.__name__\n",
    "    )\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6421b27",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_classification_report(model_name: str,\n",
    "                                y_true: pd.Series,\n",
    "                                y_pred: pd.Series,\n",
    "                                modifiers: str) -> None:\n",
    "    print(f'{model_name} - {modifiers} - Accuracy Score: {accuracy_score(y_true=y_true, y_pred=y_pred)}')\n",
    "    print(classification_report(y_true=y_true, y_pred=y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d8275b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(model_name: str, \n",
    "                          y_true: pd.Series, \n",
    "                          y_pred: pd.Series,\n",
    "                          modifiers: str) -> None:\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "    disp.plot()\n",
    "    plt.title(f'{model_name} Classification Report - {modifiers}')\n",
    "    plt.grid(False)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9599b558",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_predictions_to_sub_file(filepath_to_sample: str,\n",
    "                                 filepath_to_save: str,\n",
    "                                 y_pred: pd.Series,\n",
    "                                 model_name: str,\n",
    "                                 modifiers: str) -> None:\n",
    "    sample_entry = pd.read_csv(filepath_to_sample)\n",
    "    df_submission = pd.DataFrame({'Id': sample_entry['Id'], 'Probability': y_pred})\n",
    "\n",
    "    df_submission.to_csv(f'{filepath_to_save}/submission_{modifiers}_{model_name}.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98034238",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_pipeline(steps: list[tuple[str, BaseEstimator]]) -> Pipeline:\n",
    "    return Pipeline(steps=steps).set_output(transform='pandas')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec3faa06",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_performance_df: pd.DataFrame = pd.DataFrame(columns=['Score'])\n",
    "model_performance_df.index = pd.MultiIndex.from_product(iterables=[[], []], names=['Model', 'Metric'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3c7ffe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_model_info_metrics(y_true: pd.Series | np.ndarray, y_pred: pd.Series | np.ndarray, y_pred_proba: pd.Series | np.ndarray, estimator_name: str) -> dict[str, Number]:\n",
    "    model_specific_info_metrics: dict[str, dict | str] = {\n",
    "        'Model_Name': estimator_name,\n",
    "        'Model_Metrics': {\n",
    "            'Accuracy': accuracy_score(y_true=y_true, y_pred=y_pred),\n",
    "            'Precision (0)': precision_score(y_true=y_true, y_pred=y_pred, pos_label=0),\n",
    "            'Recall (0)': recall_score(y_true=y_true, y_pred=y_pred, pos_label=0),\n",
    "            'F1 Score (0)': f1_score(y_true=y_true, y_pred=y_pred, pos_label=0),\n",
    "            'Precision (1)': precision_score(y_true=y_true, y_pred=y_pred, pos_label=1),\n",
    "            'Recall (1)': recall_score(y_true=y_true, y_pred=y_pred, pos_label=1),\n",
    "            'F1 Score (1)': f1_score(y_true=y_true, y_pred=y_pred, pos_label=1),\n",
    "            'ROC AUC Score': roc_auc_score(y_true=y_true, y_score=y_pred_proba),\n",
    "            'PC AUC Score': average_precision_score(y_true=y_true, y_score=y_pred_proba)\n",
    "        }\n",
    "    }\n",
    "\n",
    "    return model_specific_info_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e9c33fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_to_df(metrics_dict: dict[str, Number], estimator_name: str, old_df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df_copy: pd.DataFrame = old_df.copy()\n",
    "\n",
    "    index_iterables: list[str | list] = [[estimator_name], list(metrics_dict.keys())]\n",
    "    new_multi_index = pd.MultiIndex.from_product(iterables=index_iterables, names=['Model', 'Metric'])\n",
    "\n",
    "    new_scores = pd.DataFrame({'Score': list(metrics_dict.values())}, index=new_multi_index)\n",
    "\n",
    "    df_copy = pd.concat([df_copy, new_scores])\n",
    "    return df_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b3bd3db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_comparison_df(y_true: pd.Series | np.ndarray, \n",
    "                         y_pred: pd.Series | np.ndarray, \n",
    "                         y_pred_proba: pd.Series | np.ndarray) -> pd.DataFrame:\n",
    "    comparison_df = pd.concat(\n",
    "        [\n",
    "            y_true.rename('y_true'),\n",
    "            pd.Series(y_pred, index=y_true.index, name='y_pred'),\n",
    "            pd.Series(y_pred_proba, index=y_true.index, name='y_pred_proba')\n",
    "        ],\n",
    "        axis=1\n",
    "    )\n",
    "\n",
    "    return comparison_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d55a35b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_metrics(metrics_df: pd.DataFrame) -> None:\n",
    "    metrics = metrics_df.index.get_level_values(\"Metric\").unique()\n",
    "    models = metrics_df.index.get_level_values(\"Model\").unique()\n",
    "    n_metrics = len(metrics)\n",
    "\n",
    "    colors = ['red', 'orange', 'yellow', 'blue', 'black']\n",
    "    color_map = dict(zip(models, colors))\n",
    "\n",
    "    ncols = 2\n",
    "    nrows = (n_metrics + ncols - 1) // ncols\n",
    "\n",
    "    fig, axes = plt.subplots(nrows=nrows, ncols=ncols, figsize=(12, 3 * nrows), sharex=True)\n",
    "    axes = axes.flatten()\n",
    "\n",
    "    for idx, metric in enumerate(metrics):\n",
    "        ax = axes[idx]\n",
    "        ax.set_title(metric)\n",
    "\n",
    "        for model in models:\n",
    "            score = metrics_df.loc[(model, metric), \"Score\"]\n",
    "            color = color_map[model]\n",
    "\n",
    "            ax.hlines(\n",
    "                y=score,\n",
    "                xmin=0,\n",
    "                xmax=1,\n",
    "                label=model,\n",
    "                color=color\n",
    "            )\n",
    "            \n",
    "            ax.text(1.02, score, f\"{score:.3f}\", va='center', fontsize=8)\n",
    "        \n",
    "        ax.set_xlim(0, 1)\n",
    "        ax.tick_params(left=True, labelleft=True)\n",
    "        ax.grid(True)\n",
    "\n",
    "    fig.suptitle(\"Model Comparison by Metric\", fontsize=16)\n",
    "    fig.supylabel(\"Score\", fontsize=12)\n",
    "\n",
    "    handles, labels = axes[0].get_legend_handles_labels()\n",
    "    fig.legend(handles, labels, loc='upper center', ncol=len(models), bbox_to_anchor=(0.5, 1.02))\n",
    "    fig.legend(handles, labels, loc='lower center', ncol=len(models), bbox_to_anchor=(0.5, -0.02))\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0369a4c",
   "metadata": {},
   "source": [
    "## Models Training - Baseline Performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7914632b",
   "metadata": {},
   "source": [
    "In order to observe the efficiency of dataset transformations and to compare model accuracy with the default model behavior on the unchanged dataset, with basic transformations that will ensure fit and predict workflows, training models with default parameters is done, which is known as baseline performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7b16dac",
   "metadata": {},
   "source": [
    "### Utils - Baseline Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88c4a5e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_names: list[str] = ['K-Nearest Neighbors Classifier (BP)', 'LightGBM Classifier (BP)', 'Logistic Regression (BP)', 'Random Forest Classifier (BP)', 'XGBoost Classifier (BP)']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "327c223b",
   "metadata": {},
   "source": [
    "### Basic Transformations\n",
    "Below are Transformers that are slightly changing the dataset in order to make model training possible, such as missing values imputation. At the same time, useless column that is responsible for ID is dropped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5de9341b",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer_dropper_id = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('drop_id', 'drop', ['Unnamed: 0'])\n",
    "    ],\n",
    "    remainder='passthrough',\n",
    "    verbose_feature_names_out=False\n",
    ").set_output(transform='pandas')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "370de74d",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer_log = FunctionTransformer(\n",
    "    func=np.log1p,\n",
    "    inverse_func=np.expm1,\n",
    "    validate=False,\n",
    ").set_output(transform='pandas')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0f6e596",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mice_imputer: MICE = MICE()\n",
    "simple_imputer_median: SimpleImputer = SimpleImputer(strategy='median').set_output(transform='pandas')\n",
    "simple_imputer_mean: SimpleImputer = SimpleImputer(strategy='mean').set_output(transform='pandas')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9f24350",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class MICE_Wrapper(BaseEstimator, TransformerMixin):\n",
    "#     def __init__(self, mice: MICE):\n",
    "#         self.mice = mice\n",
    "    \n",
    "#     def fit(self, X, y = None):\n",
    "#         return self\n",
    "    \n",
    "#     def transform(self, X):\n",
    "#         X_copy = X.copy()\n",
    "#         self.mice.apply(df=X_copy, columns=X_copy.columns)\n",
    "#         return X_copy\n",
    "\n",
    "#     def set_output(self, *, transform = None):\n",
    "#         return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f632240f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mice_wrapper: MICE_Wrapper = MICE_Wrapper(mice=mice_imputer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b2b4fa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "null_transformer = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('impute_num_dependents', simple_imputer_median, ['NumberOfDependents']),\n",
    "        # ('impute_mon_income', mice_wrapper),\n",
    "        ('impute_mon_income', simple_imputer_mean, ['MonthlyIncome'])\n",
    "    ],\n",
    "    remainder='passthrough',\n",
    "    verbose_feature_names_out=False\n",
    ").set_output(transform='pandas')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e8670df",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_steps: list[tuple[str, TransformerMixin]] = [\n",
    "    ('drop_id', transformer_dropper_id),\n",
    "    ('impute_null', null_transformer),\n",
    "    # ('log_transform', transformer_log),\n",
    "    # ('impute_null_2', mice_wrapper)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62accef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_transform_pipeline: Pipeline = create_pipeline(\n",
    "    steps=pipeline_steps\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b82bb598",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_zip_tf = fit_transform_pipeline.fit_transform(\n",
    "    X=X_train_zip,\n",
    "    y=y_train_zip\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ad56196",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_zip_tf = fit_transform_pipeline.transform(\n",
    "    X=X_test_zip\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91593c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_transform_pipeline: Pipeline = create_pipeline(\n",
    "    steps=pipeline_steps\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e9aca86",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_sub_tf = fit_transform_pipeline.fit_transform(\n",
    "    X=X_train_sub,\n",
    "    y=y_train_sub\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad7a2237",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_sub_tf = fit_transform_pipeline.transform(\n",
    "    X=X_test_sub\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c78d56c",
   "metadata": {},
   "source": [
    "### Light Gradient Boost Model (LightGBM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d66e56cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "lightgbm_classifier = LGBMClassifier(n_jobs=-1, \n",
    "                                   random_state=42, \n",
    "                                   device='gpu', \n",
    "                                   verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92d01611",
   "metadata": {},
   "source": [
    "#### Local Scoring Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4332c2b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "lightgbm_classifier.fit(X=X_train_zip_tf, y=y_train_zip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28042aa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_roc_curve_from_estimator(X=X_test_zip_tf, y=y_test_zip, estimator=lightgbm_classifier, estimator_name='LightGBM Classifier')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5616cbdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat_zip_proba = lightgbm_classifier.predict_proba(X=X_test_zip_tf)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d0ca2bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc_score(y_true=y_test_zip, y_score=y_hat_zip_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b570a61d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_roc_curve_from_probabilities(y_true=y_test_zip, y_prob_pred=y_hat_zip_proba, estimator_name='LightGBM Classifier')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84445ae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat_zip = lightgbm_classifier.predict(X=X_test_zip_tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a793ea7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_classification_report(model_name='LightGBM Classifier',\n",
    "                            y_true=y_test_zip,\n",
    "                            y_pred=y_hat_zip,\n",
    "                            modifiers='Baseline Performance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adc9bbb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(model_name='LightGBM',\n",
    "                      y_true=y_test_zip,\n",
    "                      y_pred=y_hat_zip,\n",
    "                      modifiers='Baseline Performance')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31109d30",
   "metadata": {},
   "source": [
    "As it may be seen, due to the fact that this dataset is highly imbalanced, accuracy is high, since model tends to predict only negative values, therefore precision, recall and F1 Score are very important, since they offer information about minority class separately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eb28c7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_info_metrics: dict[str, dict | str] = compute_model_info_metrics(y_true=y_test_zip, y_pred=y_hat_zip, y_pred_proba=y_hat_zip_proba, estimator_name='LightGBM Classifier (BP)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf03de01",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_performance_df = add_to_df(metrics_dict=model_info_metrics['Model_Metrics'], estimator_name=model_info_metrics['Model_Name'], old_df=model_performance_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "668697bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_performance_df.xs('LightGBM Classifier (BP)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9503841",
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison_df = create_comparison_df(y_true=y_test_zip, y_pred=y_hat_zip, y_pred_proba=y_hat_zip_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaf3e8aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison_df[comparison_df['y_true'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36c7b1f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison_df[comparison_df['y_true'] == 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf172589",
   "metadata": {},
   "source": [
    "#### Kaggle Submission Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "273afb6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "lightgbm_classifier = LGBMClassifier(n_jobs=-1, \n",
    "                                   random_state=42, \n",
    "                                   device='gpu', \n",
    "                                   verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d8f334e",
   "metadata": {},
   "outputs": [],
   "source": [
    "lightgbm_classifier.fit(X=X_train_sub_tf, y=y_train_sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56e28e85",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat_sub_proba = lightgbm_classifier.predict_proba(X=X_test_sub_tf)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcffa889",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_predictions_to_sub_file(filepath_to_sample='dataset/sampleEntry.csv',\n",
    "                             filepath_to_save='dataset/submissions',\n",
    "                             y_pred=y_hat_sub_proba,\n",
    "                             model_name='lightgbm',\n",
    "                             modifiers='default_bp')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7629065b",
   "metadata": {},
   "source": [
    "Kaggle Score: `0.86675 | 0.86043`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa7a2a39",
   "metadata": {},
   "source": [
    "### eXtreme Gradient Boosting (XGBoost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e919aca",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgboost_classifier = XGBClassifier(n_jobs=-1, \n",
    "                                 random_state=42, \n",
    "                                 device='gpu', \n",
    "                                 verbosity=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc880e17",
   "metadata": {},
   "source": [
    "#### Local Scoring Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13dc5413",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgboost_classifier.fit(X=X_train_zip_tf, y=y_train_zip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f23c1917",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_roc_curve_from_estimator(X=X_test_zip_tf, y=y_test_zip, estimator=xgboost_classifier, estimator_name='XGBoost Classifier - BP')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bb0ffbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat_zip_proba = xgboost_classifier.predict_proba(X=X_test_zip_tf)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "036fdf5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_roc_curve_from_probabilities(y_true=y_test_zip, y_prob_pred=y_hat_zip_proba, estimator_name='XGBoost Classifier - BP')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fb3a617",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat_zip = xgboost_classifier.predict(X=X_test_zip_tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95fe84a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_classification_report(model_name='XGBoost Classifier',\n",
    "                            y_true=y_test_zip,\n",
    "                            y_pred=y_hat_zip,\n",
    "                            modifiers='Baseline Performance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f434ce7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(model_name='XGBoost',\n",
    "                      y_true=y_test_zip,\n",
    "                      y_pred=y_hat_zip,\n",
    "                      modifiers='Baseline Performance')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00f26b5d",
   "metadata": {},
   "source": [
    "As it may be seen, due to the fact that this dataset is highly imbalanced, accuracy is high, since model tends to predict only negative values, therefore precision, recall and F1 Score are very important, since they offer information about minority class separately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad86e039",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_info_metrics: dict[str, dict | str] = compute_model_info_metrics(y_true=y_test_zip, y_pred=y_hat_zip, y_pred_proba=y_hat_zip_proba, estimator_name='XGBoost Classifier (BP)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4da531b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_performance_df = add_to_df(metrics_dict=model_info_metrics['Model_Metrics'], estimator_name=model_info_metrics['Model_Name'], old_df=model_performance_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb5e081d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_performance_df.xs('XGBoost Classifier (BP)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "774ebffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison_df = create_comparison_df(y_true=y_test_zip, y_pred=y_hat_zip, y_pred_proba=y_hat_zip_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2658d5af",
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison_df[comparison_df['y_true'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c486ff16",
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison_df[comparison_df['y_true'] == 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "707c4dc2",
   "metadata": {},
   "source": [
    "#### Kaggle Submission Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42fb841c",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgboost_classifier = XGBClassifier(n_jobs=-1, \n",
    "                                   random_state=42, \n",
    "                                   device='gpu', \n",
    "                                   verbosity=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2db00188",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgboost_classifier.fit(X=X_train_sub_tf, y=y_train_sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "248e1261",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat_sub_proba = xgboost_classifier.predict_proba(X=X_test_sub_tf)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3658064",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_predictions_to_sub_file(filepath_to_sample='dataset/sampleEntry.csv',\n",
    "                             filepath_to_save='dataset/submissions',\n",
    "                             y_pred=y_hat_sub_proba,\n",
    "                             model_name='xgboost',\n",
    "                             modifiers='default_bp')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37a01397",
   "metadata": {},
   "source": [
    "Kaggle Score: `0.85811 | 0.85248`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4551bfe",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6835b4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_regressor = LogisticRegression(n_jobs=-1, \n",
    "                                        verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e9b9634",
   "metadata": {},
   "source": [
    "#### Local Scoring Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f059972c",
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_regressor.fit(X=X_train_zip_tf, y=y_train_zip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61e7f6b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_roc_curve_from_estimator(X=X_test_zip_tf, y=y_test_zip, estimator=logistic_regressor, estimator_name='Logistic Regression (BP)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "860eb813",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat_zip_proba = logistic_regressor.predict_proba(X=X_test_zip_tf)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf283450",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_roc_curve_from_probabilities(y_true=y_test_zip, y_prob_pred=y_hat_zip_proba, estimator_name='Logistic Regression (BP)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49409407",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat_zip = logistic_regressor.predict(X=X_test_zip_tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf10d8f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_classification_report(model_name='Logistic Regressor',\n",
    "                            y_true=y_test_zip,\n",
    "                            y_pred=y_hat_zip,\n",
    "                            modifiers='Baseline Performance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c025012d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(model_name='Logistic Regressor',\n",
    "                      y_true=y_test_zip,\n",
    "                      y_pred=y_hat_zip,\n",
    "                      modifiers='Baseline Performance')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "365c7ef0",
   "metadata": {},
   "source": [
    "As it may be seen, due to the fact that this dataset is highly imbalanced, accuracy is high, since model tends to predict only negative values, therefore precision, recall and F1 Score are very important, since they offer information about minority class separately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b68217e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_info_metrics: dict[str, dict | str] = compute_model_info_metrics(y_true=y_test_zip, y_pred=y_hat_zip, y_pred_proba=y_hat_zip_proba, estimator_name='Logistic Regression (BP)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46359844",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_performance_df = add_to_df(metrics_dict=model_info_metrics['Model_Metrics'], estimator_name=model_info_metrics['Model_Name'], old_df=model_performance_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f8197b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_performance_df.xs('Logistic Regression (BP)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83c877d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison_df = create_comparison_df(y_true=y_test_zip, y_pred=y_hat_zip, y_pred_proba=y_hat_zip_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ae3c81a",
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison_df[comparison_df['y_true'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a90c796",
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison_df[comparison_df['y_true'] == 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eed09e27",
   "metadata": {},
   "source": [
    "#### Kaggle Submission Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bee303d",
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_regressor = LogisticRegression(n_jobs=-1, \n",
    "                                        verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c047129",
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_regressor.fit(X=X_train_sub_tf, y=y_train_sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f86af2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat_sub = logistic_regressor.predict_proba(X=X_test_sub_tf)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "288b7091",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_predictions_to_sub_file(filepath_to_sample='dataset/sampleEntry.csv',\n",
    "                             filepath_to_save='dataset/submissions',\n",
    "                             y_pred=y_hat_sub,\n",
    "                             model_name='logistic',\n",
    "                             modifiers='default_bp')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d2c7458",
   "metadata": {},
   "source": [
    "Kaggle Score: `0.83524 | 0.82670`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a8bb70e",
   "metadata": {},
   "source": [
    "### Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81955fd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_forest_classifier = RandomForestClassifier(n_jobs=-1, \n",
    "                                                  random_state=42, \n",
    "                                                  verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56d7fdb5",
   "metadata": {},
   "source": [
    "#### Local Scoring Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fece7c5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_forest_classifier.fit(X=X_train_zip_tf, y=y_train_zip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80989cdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_roc_curve_from_estimator(X=X_test_zip_tf, y=y_test_zip, estimator=random_forest_classifier, estimator_name='Random Forest Classifier - BP')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d75f33b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat_zip_proba = random_forest_classifier.predict_proba(X=X_test_zip_tf)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c407c984",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_roc_curve_from_probabilities(y_true=y_test_zip, y_prob_pred=y_hat_zip_proba, estimator_name='Random Forest Classifier - BP')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d5a4ea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat_zip = random_forest_classifier.predict(X=X_test_zip_tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64961d53",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_classification_report(model_name='Random Forest Classifier',\n",
    "                            y_true=y_test_zip,\n",
    "                            y_pred=y_hat_zip,\n",
    "                            modifiers='Baseline Performance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2edbbcaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(model_name='Random Forest',\n",
    "                      y_true=y_test_zip,\n",
    "                      y_pred=y_hat_zip,\n",
    "                      modifiers='Baseline Performance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "990fa91e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_info_metrics: dict[str, dict | str] = compute_model_info_metrics(y_true=y_test_zip, y_pred=y_hat_zip, y_pred_proba=y_hat_zip_proba, estimator_name='Random Forest Classifier (BP)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbec1146",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_performance_df = add_to_df(metrics_dict=model_info_metrics['Model_Metrics'], estimator_name=model_info_metrics['Model_Name'], old_df=model_performance_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a21bd831",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_performance_df.xs('Random Forest Classifier (BP)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c56104a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison_df = create_comparison_df(y_true=y_test_zip, y_pred=y_hat_zip, y_pred_proba=y_hat_zip_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db92c704",
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison_df[comparison_df['y_true'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0ac276b",
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison_df[comparison_df['y_true'] == 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "815a3418",
   "metadata": {},
   "source": [
    "#### Kaggle Submission Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f220fa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_forest_classifier = RandomForestClassifier(n_jobs=-1, \n",
    "                                                  random_state=42, \n",
    "                                                  verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4765b1f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_forest_classifier.fit(X=X_train_sub_tf, y=y_train_sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "479d3ca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat_sub = random_forest_classifier.predict_proba(X=X_test_sub_tf)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67e57560",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_predictions_to_sub_file(filepath_to_sample='dataset/sampleEntry.csv',\n",
    "                             filepath_to_save='dataset/submissions',\n",
    "                             y_pred=y_hat_sub,\n",
    "                             model_name='randomForest',\n",
    "                             modifiers='default_bp')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e76914ad",
   "metadata": {},
   "source": [
    "Kaggle Score: `0.84255 | 0.83637`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "966b6c51",
   "metadata": {},
   "source": [
    "### K-Nearest Neighbors Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b35d6b76",
   "metadata": {},
   "outputs": [],
   "source": [
    "k_nearest_neighbors_classifier = KNeighborsClassifier(n_jobs=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93e13afb",
   "metadata": {},
   "source": [
    "#### Local Scoring Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "455f794a",
   "metadata": {},
   "outputs": [],
   "source": [
    "k_nearest_neighbors_classifier.fit(X=X_train_zip_tf, y=y_train_zip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4de2046a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_roc_curve_from_estimator(X=X_test_zip_tf, y=y_test_zip, estimator=k_nearest_neighbors_classifier, estimator_name='K-Nearest Neighbors Classifier - BP')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b880b77d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat_zip_proba = k_nearest_neighbors_classifier.predict_proba(X=X_test_zip_tf)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "108fdb9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_roc_curve_from_probabilities(y_true=y_test_zip, y_prob_pred=y_hat_zip_proba, estimator_name='K-Nearest Neighbors Classifier - BP')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aecdf27b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat_zip = k_nearest_neighbors_classifier.predict(X=X_test_zip_tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f1311f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_classification_report(model_name='K-Nearest Neighbors Classifier',\n",
    "                            y_true=y_test_zip,\n",
    "                            y_pred=y_hat_zip,\n",
    "                            modifiers='Baseline Performance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55c7ee50",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(model_name='K-Nearest Neighbors',\n",
    "                      y_true=y_test_zip,\n",
    "                      y_pred=y_hat_zip,\n",
    "                      modifiers='Baseline Performance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b38595b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_info_metrics: dict[str, dict | str] = compute_model_info_metrics(y_true=y_test_zip, y_pred=y_hat_zip, y_pred_proba=y_hat_zip_proba, estimator_name='K-Nearest Neighbors Classifier (BP)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7922715",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_performance_df = add_to_df(metrics_dict=model_info_metrics['Model_Metrics'], estimator_name=model_info_metrics['Model_Name'], old_df=model_performance_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e9eaa72",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_performance_df.xs('K-Nearest Neighbors Classifier (BP)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b3d2bc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison_df = create_comparison_df(y_true=y_test_zip, y_pred=y_hat_zip, y_pred_proba=y_hat_zip_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55ab7308",
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison_df[comparison_df['y_true'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aac3d18",
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison_df[comparison_df['y_true'] == 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "091d6fb9",
   "metadata": {},
   "source": [
    "#### Kaggle Submission Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f511b280",
   "metadata": {},
   "outputs": [],
   "source": [
    "k_nearest_neighbors_classifier = KNeighborsClassifier(n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12f24408",
   "metadata": {},
   "outputs": [],
   "source": [
    "k_nearest_neighbors_classifier.fit(X=X_train_sub_tf, y=y_train_sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f81897af",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat_sub = k_nearest_neighbors_classifier.predict_proba(X=X_test_sub_tf)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76e167bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_predictions_to_sub_file(filepath_to_sample='dataset/sampleEntry.csv',\n",
    "                             filepath_to_save='dataset/submissions',\n",
    "                             y_pred=y_hat_sub,\n",
    "                             model_name='knn',\n",
    "                             modifiers='default_bp')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2deaa8df",
   "metadata": {},
   "source": [
    "Kaggle Score: `0.74397 | 0.73065`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66853b93",
   "metadata": {},
   "source": [
    "### Baseline Performance Summary\n",
    "Since dataset is highly imbalanced, all models tend to predict probability values close to `0` for a vast majority of test rows, that are also mostly close to `0`, therefore their accuracy on Kaggle website is pretty similar, fluctuating around values of $\\approx 0.74$ achieved by K-Nearest Neighbors Classifier to $\\approx 0.86$ achieved by LightGBM Classifier, thus an important step is class balancing, in order to provide better scores of Precision, Recall and ROC-AUC, that are very useful in determination of real behavior of the model and its predictions.\n",
    "\n",
    "#### Kaggle Results Table:\n",
    "| **Classifier Name**   | **Modifiers** | **Private Score** | **Public Score** |\n",
    "|-----------------------|---------------|-------------------|------------------|\n",
    "| _LightGBM_            |       BP      |      0.86043      |      0.86043     |\n",
    "| _XGBoost_             |       BP      |      0.85911      |      0.85248     |\n",
    "| _Logistic Regression_ |       BP      |      0.83524      |      0.82670     |\n",
    "| _Random Forest_       |       BP      |      0.84255      |      0.83637     |\n",
    "| _K-Nearest Neighbors_ |       BP      |      0.74397      |      0.73065     |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef4acab3",
   "metadata": {},
   "source": [
    "#### Local Perfomance Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dce7bf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_performance_df.loc[model_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56dec522",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_metrics(metrics_df=model_performance_df.loc[model_names])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b41b3c1",
   "metadata": {},
   "source": [
    "Was observed that all models suffer from misclassification of test samples with positive label, as a result of highly imbalanced dataset ($\\approx 93\\%$ negative labels against $\\approx 7\\%$ positive labels). As a mitigation strategy for this is to implement Class Balancing methods, either Undersampling, which will reduce the majority class to match closely the minority class, or Oversampling, that will create new samples of minority class to reduce the proportion of majority class, use `scale_pos_weight` or `class_weight` hyperparameters for trained models, which will associate weights to classes based on their class frequencies in the dataset. Since ROC-AUC Score is high for boosted trees algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab9422bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: scale pos weight xgboost lightgbm ratio negative/positive classes, trees handle automatic Null values, FE + FSc + OUTLIERS + CLASS BALANCING + FSel + etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bbccc5e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
