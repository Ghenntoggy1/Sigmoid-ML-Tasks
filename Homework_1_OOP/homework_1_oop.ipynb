{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Homework #1 - Object-Oriented Programming Principles.\n",
    "\n",
    "In this homework I had to implement all my knowledge regarding the OOP principles into practice.\n",
    "\n",
    "## Objective: Create a simplified machine learning pipeline that demonstrates Object-Oriented Programming (OOP) principles\n",
    "\n",
    "### Data Specification:\n",
    "* X: A list (or list of lists) representing your features. For simplicity, you can assume\n",
    "one-dimensional features (e.g., [1, 2, 3]), where each number could represent the\n",
    "house size for each different example in your data\n",
    "* y: A list of numeric values representing labels or target values (e.g., [10, 14, 12] for\n",
    "regression - house price, or [0, 1, 0] for classification - pricing category: 0 - not\n",
    "expensive, 1 - expensive)\n",
    "\n",
    "### Classes to implement:\n",
    "\n",
    "#### Base Class: MLModel\n",
    "* Define two methods, fit(X, y) and predict(X). Both should raise NotImplementedError by default. This ensures that child classes are responsible for implementing the details.\n",
    "\n",
    "#### Child Classes:\n",
    "* DummyClassifier\n",
    "  * The fit(X, y) method should compute and store the most common target class based on y (store it in self.__mode)\n",
    "  * The predict(X) method should return a list of the same length as X, where each element would be the computed value self.__mode\n",
    "* MeanRegressor:\n",
    "  * In the fit(X, y) method, compute the mean of y and store it (e.g., self.__mean).\n",
    "  * In the predict(X) method, return this stored mean for every input (e.g., \\[self.__mean, self.__mean, ...\\]).\n",
    "\n",
    "#### Dataset Class:\n",
    "* During object initialization, store the features (X) and targets (y) in private attributes\n",
    "(e.g., __features and __targets).\n",
    "* Provide a method get_data() to return (X, y).\n",
    "* Implement a split(train_fraction=0.8) method that returns (X_train, y_train), (X_test, y_test) by slicing the data.\n",
    "\n",
    "### Final Demonstration:\n",
    "* Create variables X and y with any values, load them into your Dataset, and split the data into X_train, y_train, X_test, y_test by calling split method\n",
    "* Instantiate each model class, train them on (X_train, y_train) by calling fit method, then predict on X_test.\n",
    "* Print out the predictions for each model.\n",
    "* Highlight Polymorphism, Encapsulation, and Inheritance through your implementation and demonstration"
   ],
   "id": "24fa08cac6663104"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Base class - MLModel\n",
    "In the cell below, I specify a Base class (sort of abstract class) that will be \"implemented\" by its subclasses. It has 2 \"abstract\" methods:\n",
    "* fit(X, y) - that will take the list or list of lists parameter X (feature / features) and y - list of numeric values (target).\n",
    "* predict(X) - that will take the list or list of lists parameter X (feature / features).\n",
    "\n",
    "Both of the methods are not actually abstract in the direct sense, but we simulate that behavior by making them raise NotImplementedError, that will mean that the method are abstract."
   ],
   "id": "5da8c5c6ed525471"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-01-22T14:18:20.936938Z",
     "start_time": "2025-01-22T14:18:20.933707Z"
    }
   },
   "source": [
    "class MLModel:\n",
    "    def fit(self, X: list[int | float] | list[list[int | float]], y: list) -> None:\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def predict(self, X: list[int | float] | list[list[int | float]]):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    # This will be used to demonstrate the use of Inheritance in the Final Demonstration\n",
    "    def inherited_method(self):\n",
    "        print(\"INHERITED METHOD EXAMPLE!\")"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Subclass #1 - DummyClassifier\n",
    "In the cell below, I present the DummyClassifier class, that will \"implement\" the MLModel \"abstract\" class (actually the DummyClassifier(MLModel) is about the Inheritance), making the\n",
    "DummyClassifier a subclass of the MLModel base class. In this case, it should override the methods from its parent class (implement them).\n",
    "* fit(X, y) - for this method, it will find the most common Target Class in the y parameter (list of Target Variables) via the use of Counter.most_common() method that will return a list\n",
    "of tuples of type (value, occurrence), and I will take the value from the tuple that I get from the list.\n",
    "* predict(X) - for this method, I will just return a list that has repeating the self.__mode variable using list comprehension."
   ],
   "id": "500662b60bcca0b7"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-22T14:18:21.154980Z",
     "start_time": "2025-01-22T14:18:21.141282Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from overrides import override\n",
    "from collections import Counter\n",
    "\n",
    "from Homework_1_OOP.Models.MLModel import MLModel\n",
    "\n",
    "\n",
    "class DummyClassifier(MLModel):\n",
    "    def __init__(self):\n",
    "        self.__mode: int = 0\n",
    "\n",
    "    @override\n",
    "    def fit(self, X: list[int | float] | list[list[int | float]], y: list) -> None:\n",
    "        if set(y) != {0, 1}:\n",
    "            raise ValueError(f\"y must contain only 0 and 1 values - set(y) = {set(y)}\")\n",
    "        if len(y) == 0:\n",
    "            raise ValueError(\"y contains no values inside.\")\n",
    "        if len(X) != len(y):\n",
    "            raise ValueError(f\"X and y must be of the same length - len(X) = {len(X)} and len(y) = {len(y)}.\")\n",
    "\n",
    "        occurrence_count = Counter(y)\n",
    "        self.__mode = occurrence_count.most_common(1)[0][0] # most_common(1) => only one most common value (still list of tuples),\n",
    "                                                            # most_common(1)[0] => return the tuple (value, occurrences),\n",
    "                                                            # most_common(1)[0][0] => return the most common value.\n",
    "    @override\n",
    "    def predict(self, X: list[int | float] | list[list[int | float]]) -> list:\n",
    "        return [self.__mode for _ in range(len(X))]"
   ],
   "id": "ce14a65e0747ac1c",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Subclass #2 - MeanRegressor\n",
    "In the cell below, I present the MeanRegressor class, that will \"implement\" the MLModel \"abstract\" class, making the\n",
    "MeanRegressor a subclass of the MLModel base class. In this case, it should override the methods from its parent class (implement them).\n",
    "* fit(X, y) - for this method, it will find the mean value of the y parameter (list of Target Variables) via the use of ...\n",
    "* predict(X) - for this method, I will just return a list that has repeating the self.__mean variable for each input, using, again, list comprehension."
   ],
   "id": "11ec4d403d4a03fe"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-22T14:18:21.163325Z",
     "start_time": "2025-01-22T14:18:21.158982Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from overrides import override\n",
    "\n",
    "from Homework_1_OOP.Models.MLModel import MLModel\n",
    "\n",
    "\n",
    "class MeanRegressor(MLModel):\n",
    "    def __init__(self):\n",
    "        self.__mean: float = 0.0\n",
    "\n",
    "    @override\n",
    "    def fit(self, X: list[int | float] | list[list[int | float]], y: list) -> None:\n",
    "        if len(X) != len(y):\n",
    "            raise ValueError(f\"X and y must be of the same length - len(X) = {len(X)} and len(y) = {len(y)}\")\n",
    "\n",
    "        self.__mean = sum(y) / len(y)\n",
    "\n",
    "    @override\n",
    "    def predict(self, X: list[int | float] | list[list[int | float]]) -> list:\n",
    "        return [self.__mean for _ in range(len(X))]"
   ],
   "id": "17cd4772c5c16f41",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Class - Dataset\n",
    "In the cell below, I present the Dataset class, that will hold the Features and Target variables inside of it (using Constructor) and will offer the following methods:\n",
    "* get_data() - it will return both features and targets that were assigned to the object of type Dataset,\n",
    "* split(train_fraction) - it will split the dataset based on a train fraction float that will show the percentage of the data in the Training set and the remaining - in the Test set."
   ],
   "id": "7de5c0e705368068"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-22T14:18:21.173164Z",
     "start_time": "2025-01-22T14:18:21.169307Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import math\n",
    "\n",
    "\n",
    "class Dataset:\n",
    "    def __init__(self, features: list | list[list], targets: list):\n",
    "        if len(features) != len(targets):\n",
    "            raise ValueError(f\"X and y must be of the same length - len(X) = {len(features)} and len(y) = {len(targets)}\")\n",
    "        self.__features = features\n",
    "        self.__targets = targets\n",
    "\n",
    "    def get_data(self) -> tuple[list, list]:\n",
    "        return self.__features, self.__targets\n",
    "\n",
    "    def split(self, train_fraction: float = 0.8) -> tuple[tuple[list, list], tuple[list, list]]:\n",
    "        if not (0.0 <= train_fraction <= 1.0):\n",
    "            raise ValueError(f\"Train Fraction should be in range from 0.0 to 1.0 - train_fraction = {train_fraction}\")\n",
    "\n",
    "        slice_index: int = math.ceil(len(self.__features) * train_fraction)\n",
    "\n",
    "        X_train: list = self.__features[:slice_index]\n",
    "        y_train: list = self.__targets[:slice_index]\n",
    "        X_test: list = self.__features[slice_index:]\n",
    "        y_test: list = self.__targets[slice_index:]\n",
    "\n",
    "        return (X_train, y_train), (X_test, y_test)"
   ],
   "id": "f892b5fff1e905ab",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Execution\n",
    "For the Final Demonstration, I will present the step-by-step execution of the code that embeds all of the above functionalities."
   ],
   "id": "762d2c5fc442606a"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### Step 1\n",
    "For this Step, I initialize a sample dataset, with arbitrary values:"
   ],
   "id": "51aa5b4c99d32e5d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-22T14:18:21.184361Z",
     "start_time": "2025-01-22T14:18:21.178986Z"
    }
   },
   "cell_type": "code",
   "source": [
    "X_classification: list = [5, 2, 1, 4, 6, 7, 4, 1, 2, 3]\n",
    "X_classification_multiple: list[list] = [\n",
    "    [0, 2, 1, 4, 6, 7, 4, 1, 2, 3],\n",
    "    [1, 2, 1, 4, 6, 7, 4, 1, 2, 3],\n",
    "    [2, 2, 1, 4, 6, 7, 4, 1, 2, 3],\n",
    "    [3, 2, 1, 4, 6, 7, 4, 1, 2, 3],\n",
    "    [4, 2, 1, 4, 6, 7, 4, 1, 2, 3],\n",
    "    [5, 2, 1, 4, 6, 7, 4, 1, 2, 3],\n",
    "    [6, 2, 1, 4, 6, 7, 4, 1, 2, 3],\n",
    "    [7, 2, 1, 4, 6, 7, 4, 1, 2, 3],\n",
    "    [8, 2, 1, 4, 6, 7, 4, 1, 2, 3],\n",
    "    [9, 2, 1, 4, 6, 7, 4, 1, 2, 3]\n",
    "]\n",
    "y_classification: list = [1, 1, 0, 0, 1, 0, 1, 1, 1, 1]\n",
    "\n",
    "X_regression: list = [1, 7, 25, 12, 10, 23, 10, 11, 9, 34]\n",
    "X_regression_multiple: list[list] = [\n",
    "    [0, 7, 25, 12, 10, 23, 10, 11, 9, 34],\n",
    "    [1, 7, 25, 12, 10, 23, 10, 11, 9, 34],\n",
    "    [2, 7, 25, 12, 10, 23, 10, 11, 9, 34],\n",
    "    [3, 7, 25, 12, 10, 23, 10, 11, 9, 34],\n",
    "    [4, 7, 25, 12, 10, 23, 10, 11, 9, 34],\n",
    "    [5, 7, 25, 12, 10, 23, 10, 11, 9, 34],\n",
    "    [6, 7, 25, 12, 10, 23, 10, 11, 9, 34],\n",
    "    [7, 7, 25, 12, 10, 23, 10, 11, 9, 34],\n",
    "    [8, 7, 25, 12, 10, 23, 10, 11, 9, 34],\n",
    "    [9, 7, 25, 12, 10, 23, 10, 11, 9, 34]\n",
    "]\n",
    "y_regression: list = [50, 10, 100, 15, 13, 4, 7, 10, 24, 76] # sum = 209 for training set with 0.8 split. mean = 209 / 8 = 26.125"
   ],
   "id": "819065f060734530",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### Step 2\n",
    "Next, I will instantiate a Dataset object and I will use its split method on the dataset described above."
   ],
   "id": "82c805815a7af692"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-22T14:18:21.203461Z",
     "start_time": "2025-01-22T14:18:21.198933Z"
    }
   },
   "cell_type": "code",
   "source": [
    "dataset_classification: Dataset = Dataset(features=X_classification, targets=y_classification)\n",
    "dataset_classification_multiple: Dataset = Dataset(features=X_classification_multiple, targets=y_classification)\n",
    "dataset_regression: Dataset = Dataset(features=X_regression, targets=y_regression)\n",
    "dataset_regression_multiple: Dataset = Dataset(features=X_regression_multiple, targets=y_regression)\n",
    "\n",
    "datasets_list: list[Dataset] = [dataset_classification, dataset_classification_multiple, dataset_regression, dataset_regression_multiple]\n",
    "titles: list[str] = [\"CLASSIFICATION\", \"CLASSIFICATION MULTIPLE FEATURES\", \"REGRESSION\", \"REGRESSION MULTIPLE FEATURES\"]\n",
    "datasets_dict: dict = dict(zip(titles, datasets_list))\n",
    "\n",
    "for index, (title, dataset) in enumerate(datasets_dict.items()):\n",
    "    print(f\"Case {index + 1}: {title}\")\n",
    "    (X_train, y_train), (X_test, y_test) = dataset.split()\n",
    "    print(f\"X_train = {X_train}\")\n",
    "    print(f\"y_train = {y_train}\")\n",
    "    print(f\"X_test = {X_test}\")\n",
    "    print(f\"y_test = {y_test}\")\n",
    "    datasets_dict[title] = (X_train, y_train), (X_test, y_test)"
   ],
   "id": "db3109b343be23ec",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Case 1: CLASSIFICATION\n",
      "X_train = [5, 2, 1, 4, 6, 7, 4, 1]\n",
      "y_train = [1, 1, 0, 0, 1, 0, 1, 1]\n",
      "X_test = [2, 3]\n",
      "y_test = [1, 1]\n",
      "Case 2: CLASSIFICATION MULTIPLE FEATURES\n",
      "X_train = [[0, 2, 1, 4, 6, 7, 4, 1, 2, 3], [1, 2, 1, 4, 6, 7, 4, 1, 2, 3], [2, 2, 1, 4, 6, 7, 4, 1, 2, 3], [3, 2, 1, 4, 6, 7, 4, 1, 2, 3], [4, 2, 1, 4, 6, 7, 4, 1, 2, 3], [5, 2, 1, 4, 6, 7, 4, 1, 2, 3], [6, 2, 1, 4, 6, 7, 4, 1, 2, 3], [7, 2, 1, 4, 6, 7, 4, 1, 2, 3]]\n",
      "y_train = [1, 1, 0, 0, 1, 0, 1, 1]\n",
      "X_test = [[8, 2, 1, 4, 6, 7, 4, 1, 2, 3], [9, 2, 1, 4, 6, 7, 4, 1, 2, 3]]\n",
      "y_test = [1, 1]\n",
      "Case 3: REGRESSION\n",
      "X_train = [1, 7, 25, 12, 10, 23, 10, 11]\n",
      "y_train = [50, 10, 100, 15, 13, 4, 7, 10]\n",
      "X_test = [9, 34]\n",
      "y_test = [24, 76]\n",
      "Case 4: REGRESSION MULTIPLE FEATURES\n",
      "X_train = [[0, 7, 25, 12, 10, 23, 10, 11, 9, 34], [1, 7, 25, 12, 10, 23, 10, 11, 9, 34], [2, 7, 25, 12, 10, 23, 10, 11, 9, 34], [3, 7, 25, 12, 10, 23, 10, 11, 9, 34], [4, 7, 25, 12, 10, 23, 10, 11, 9, 34], [5, 7, 25, 12, 10, 23, 10, 11, 9, 34], [6, 7, 25, 12, 10, 23, 10, 11, 9, 34], [7, 7, 25, 12, 10, 23, 10, 11, 9, 34]]\n",
      "y_train = [50, 10, 100, 15, 13, 4, 7, 10]\n",
      "X_test = [[8, 7, 25, 12, 10, 23, 10, 11, 9, 34], [9, 7, 25, 12, 10, 23, 10, 11, 9, 34]]\n",
      "y_test = [24, 76]\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Exactly, here, when I create an object of class Dataset, I inject the X and y (features and targets) that will be used by the constructor in order to set them as its private fields\n",
    "inside itself. By making them private, I ensure that only the Dataset object can access them, via its own methods. In order to provide an access point to them, to see them, I have a\n",
    "method get_data() that will return them as a tuple. This will ensure the Encapsulation of the data in the Dataset."
   ],
   "id": "80f1909466ba34ab"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### Step 4\n",
    "In the next step, I will actually use both MLModels implementations in order to illustrate the algorithms in work and the use of Polymorphism and Inheritance.\n",
    "\n",
    "As I mentioned at the MLModel class description, I have a method that will be inherited by the Concrete ML Model Classes (MeanRegressor and DummyClassifier). This method will just\n",
    "print a string in the console. At the same time, I can specify that the type of the class that the variables for ML Models will hold a MLModel class, that is valid, because the\n",
    "Concrete ML Models are subclasses of the MLModel base class and they will just substitute it at the instantiation.\n"
   ],
   "id": "2ee70f5c44befcf5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-22T14:18:21.213182Z",
     "start_time": "2025-01-22T14:18:21.210304Z"
    }
   },
   "cell_type": "code",
   "source": [
    "classifier_model: MLModel = DummyClassifier()\n",
    "regression_model: MLModel = MeanRegressor()\n",
    "\n",
    "classifier_model.inherited_method()\n",
    "regression_model.inherited_method()"
   ],
   "id": "363e85528e9ca8fc",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INHERITED METHOD EXAMPLE!\n",
      "INHERITED METHOD EXAMPLE!\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Next, I will demonstrate how the Polymorphism, in the context of Overriding of methods, is working in the current hierarchy. Since both DummyClassifier and MeanRegressor implements the\n",
    "abstract class MLModel, they will override the fit(X, y) and predict(X) methods in order to implement them in their own ways."
   ],
   "id": "606168c4c3fe63c7"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-22T14:18:21.230752Z",
     "start_time": "2025-01-22T14:18:21.225087Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for index, (title, datasets) in enumerate(datasets_dict.items()):\n",
    "    print(f\"Case {index + 1}: {title}\")\n",
    "    print(f\"Dataset:\")\n",
    "    X_train = datasets[0][0]\n",
    "    y_train = datasets[0][1]\n",
    "    X_test = datasets[1][0]\n",
    "    y_test = datasets[1][1]\n",
    "    print(f\"X_train = {X_train}\")\n",
    "    print(f\"y_train = {y_train}\")\n",
    "    print(f\"X_test = {X_test}\")\n",
    "    print(f\"y_test = {y_test}\")\n",
    "    if index <= 1:\n",
    "        classifier_model.fit(X=X_train, y=y_train)\n",
    "        print(f\"Predicted classes - {classifier_model.predict(X=X_test)}\")\n",
    "    else:\n",
    "        regression_model.fit(X=X_train, y=y_train)\n",
    "        print(f\"Predicted values - {regression_model.predict(X=y_test)}\")"
   ],
   "id": "d04fb76f7e5027bc",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Case 1: CLASSIFICATION\n",
      "Dataset:\n",
      "X_train = [5, 2, 1, 4, 6, 7, 4, 1]\n",
      "y_train = [1, 1, 0, 0, 1, 0, 1, 1]\n",
      "X_test = [2, 3]\n",
      "y_test = [1, 1]\n",
      "Predicted classes - [1, 1]\n",
      "Case 2: CLASSIFICATION MULTIPLE FEATURES\n",
      "Dataset:\n",
      "X_train = [[0, 2, 1, 4, 6, 7, 4, 1, 2, 3], [1, 2, 1, 4, 6, 7, 4, 1, 2, 3], [2, 2, 1, 4, 6, 7, 4, 1, 2, 3], [3, 2, 1, 4, 6, 7, 4, 1, 2, 3], [4, 2, 1, 4, 6, 7, 4, 1, 2, 3], [5, 2, 1, 4, 6, 7, 4, 1, 2, 3], [6, 2, 1, 4, 6, 7, 4, 1, 2, 3], [7, 2, 1, 4, 6, 7, 4, 1, 2, 3]]\n",
      "y_train = [1, 1, 0, 0, 1, 0, 1, 1]\n",
      "X_test = [[8, 2, 1, 4, 6, 7, 4, 1, 2, 3], [9, 2, 1, 4, 6, 7, 4, 1, 2, 3]]\n",
      "y_test = [1, 1]\n",
      "Predicted classes - [1, 1]\n",
      "Case 3: REGRESSION\n",
      "Dataset:\n",
      "X_train = [1, 7, 25, 12, 10, 23, 10, 11]\n",
      "y_train = [50, 10, 100, 15, 13, 4, 7, 10]\n",
      "X_test = [9, 34]\n",
      "y_test = [24, 76]\n",
      "Predicted values - [26.125, 26.125]\n",
      "Case 4: REGRESSION MULTIPLE FEATURES\n",
      "Dataset:\n",
      "X_train = [[0, 7, 25, 12, 10, 23, 10, 11, 9, 34], [1, 7, 25, 12, 10, 23, 10, 11, 9, 34], [2, 7, 25, 12, 10, 23, 10, 11, 9, 34], [3, 7, 25, 12, 10, 23, 10, 11, 9, 34], [4, 7, 25, 12, 10, 23, 10, 11, 9, 34], [5, 7, 25, 12, 10, 23, 10, 11, 9, 34], [6, 7, 25, 12, 10, 23, 10, 11, 9, 34], [7, 7, 25, 12, 10, 23, 10, 11, 9, 34]]\n",
      "y_train = [50, 10, 100, 15, 13, 4, 7, 10]\n",
      "X_test = [[8, 7, 25, 12, 10, 23, 10, 11, 9, 34], [9, 7, 25, 12, 10, 23, 10, 11, 9, 34]]\n",
      "y_test = [24, 76]\n",
      "Predicted values - [26.125, 26.125]\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "As it may be seen, the results are consistent. In the next cell, I will take one specific example for regression and classification and I will try to explain it in particular",
   "id": "ac184928243ed188"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-22T14:18:21.243267Z",
     "start_time": "2025-01-22T14:18:21.239306Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"REGRESSION MODEL\")\n",
    "datasets: dict = datasets_dict.get(\"REGRESSION\")\n",
    "X_train = datasets[0][0]\n",
    "y_train = datasets[0][1]\n",
    "X_test = datasets[1][0]\n",
    "y_test = datasets[1][1]\n",
    "print(f\"X_train = {X_train}\")\n",
    "print(f\"y_train = {y_train}\")\n",
    "print(f\"X_test = {X_test}\")\n",
    "print(f\"y_test = {y_test}\")"
   ],
   "id": "1973964dc9c17bf5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REGRESSION MODEL\n",
      "X_train = [1, 7, 25, 12, 10, 23, 10, 11]\n",
      "y_train = [50, 10, 100, 15, 13, 4, 7, 10]\n",
      "X_test = [9, 34]\n",
      "y_test = [24, 76]\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-22T14:18:21.260265Z",
     "start_time": "2025-01-22T14:18:21.257071Z"
    }
   },
   "cell_type": "code",
   "source": [
    "regression_model: MLModel = MeanRegressor()\n",
    "regression_model.fit(X_train, y_train)\n",
    "print(f\"X_test: {X_test}\")\n",
    "print(f\"Predicted Values: {regression_model.predict(X_test)}\")"
   ],
   "id": "c431ce11fee65f71",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_test: [9, 34]\n",
      "Predicted Values: [26.125, 26.125]\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "In the above cell, I have the predicted Value 26.125. In order to check it, I go through the instructions by-hand and, as it may be seen below, the result is actually correct.\n",
    "$$\n",
    "\\begin{split}\n",
    "{\\vec{y}}_{train} = \\begin{pmatrix}\n",
    "50 \\cr\n",
    "10 \\cr\n",
    "100 \\cr\n",
    "15 \\cr\n",
    "13 \\cr\n",
    "4 \\cr\n",
    "7 \\cr\n",
    "10 \\cr\n",
    "\\end{pmatrix}\n",
    "\\\\[10pt]\n",
    "{sum}_{y_{train}} = \\displaystyle\\sum_{i=0}^{len({\\vec{y}}_{train})} {y_{train}^{(i)}} = 209\n",
    "\\\\[10pt]\n",
    "{mean}_{y_{train}} = \\frac{{sum}_{y_{train}}}{len(y_{train})} = \\frac{209}{8} = 26.125\n",
    "\\\\[10pt]\n",
    "\\hat{y} = \\begin{pmatrix}\n",
    "26.125 \\cr\n",
    "26.125 \\cr\n",
    "\\end{pmatrix}\n",
    "\\end{split}\n",
    "$$"
   ],
   "id": "775de3a1297f9172"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-22T14:18:21.274123Z",
     "start_time": "2025-01-22T14:18:21.270929Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"CLASSIFICATION MODEL\")\n",
    "datasets: dict = datasets_dict.get(\"CLASSIFICATION\")\n",
    "X_train = datasets[0][0]\n",
    "y_train = datasets[0][1]\n",
    "X_test = datasets[1][0]\n",
    "y_test = datasets[1][1]\n",
    "print(f\"X_train = {X_train}\")\n",
    "print(f\"y_train = {y_train}\")\n",
    "print(f\"X_test = {X_test}\")\n",
    "print(f\"y_test = {y_test}\")"
   ],
   "id": "31b0f109a58403d0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLASSIFICATION MODEL\n",
      "X_train = [5, 2, 1, 4, 6, 7, 4, 1]\n",
      "y_train = [1, 1, 0, 0, 1, 0, 1, 1]\n",
      "X_test = [2, 3]\n",
      "y_test = [1, 1]\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-22T14:18:21.291167Z",
     "start_time": "2025-01-22T14:18:21.287317Z"
    }
   },
   "cell_type": "code",
   "source": [
    "classifier_model: MLModel = DummyClassifier()\n",
    "classifier_model.fit(X_train, y_train)\n",
    "print(f\"X_test: {X_test}\")\n",
    "print(f\"Predicted Classes: {classifier_model.predict(X_test)}\")"
   ],
   "id": "1a2662582e06b982",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_test: [2, 3]\n",
      "Predicted Classes: [1, 1]\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "In the above cell, I have the predicted Class 1. In order to check it, I go through the instructions by-hand, as in previous example, and, as it may be seen below, the result is\n",
    "actually correct.\n",
    "$$\n",
    "\\begin{split}\n",
    "{\\vec{y}}_{train} = \\begin{pmatrix}\n",
    "1 \\cr\n",
    "1 \\cr\n",
    "0 \\cr\n",
    "0 \\cr\n",
    "1 \\cr\n",
    "0 \\cr\n",
    "1 \\cr\n",
    "1 \\cr\n",
    "\\end{pmatrix}\n",
    "\\\\[10pt]\n",
    "max\\_y = \\arg\\max_{y \\in {\\vec{y}}_{train}} \\left( \\text{count}(y) \\right) = 1 \\text{ (nr. of occurrences = 5)}\n",
    "\\\\[10pt]\n",
    "\\hat{y} = \\begin{pmatrix}\n",
    "1 \\cr\n",
    "1 \\cr\n",
    "\\end{pmatrix}\n",
    "\\end{split}\n",
    "$$"
   ],
   "id": "73b813745f03415c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "|In the above code, I have both models of Classification and Regression, and they implement the specific methods from each instance of the class DummyClassifier and MeanRegressor.",
   "id": "a32994a1552c3b7d"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
